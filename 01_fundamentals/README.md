# 01 - ML/AI Fundamentals

Master the mathematical and conceptual foundations for ML/AI success.

## 🎯 Learning Objectives
- Build solid mathematical foundation for ML
- Understand core ML concepts and terminology
- Learn to think in terms of data and patterns
- Develop intuition for model behavior

## 📚 Detailed Topics

### 1. Linear Algebra (Week 1, Days 1-3)
**Core Topics:**
- **Vectors**: Operations, dot product, cross product, norms
- **Matrices**: Multiplication, transpose, inverse, determinant
- **Eigenvalues/Eigenvectors**: Principal components, dimensionality reduction
- **Vector Spaces**: Basis, linear independence, span

**🎯 Focus Areas:**
- Matrix operations (90% of ML uses this)
- Understanding geometric interpretations
- Eigenvalue decomposition (critical for PCA)

**💪 Practice:**
- Implement matrix operations from scratch in NumPy
- Visualize vector operations in 2D/3D
- Build PCA algorithm manually
- **Project**: Image compression using SVD

### 2. Calculus & Optimization (Week 1, Days 4-5)
**Core Topics:**
- **Derivatives**: Partial derivatives, chain rule, gradients
- **Optimization**: Gradient descent, local/global minima
- **Multivariable Calculus**: Gradients, Hessians, Taylor series
- **Constrained Optimization**: Lagrange multipliers

**🎯 Focus Areas:**
- Gradient computation (backpropagation foundation)
- Understanding loss function landscapes
- Optimization algorithms (SGD, Adam, etc.)

**💪 Practice:**
- Implement gradient descent from scratch
- Visualize loss function surfaces
- Find optimal parameters for simple functions
- **Project**: Linear regression with manual gradient descent

### 3. Probability & Statistics (Week 1, Days 6-7)
**Core Topics:**
- **Probability Basics**: Conditional probability, Bayes' theorem
- **Distributions**: Normal, binomial, Poisson, exponential
- **Statistical Inference**: Hypothesis testing, confidence intervals
- **Bayesian vs Frequentist**: Different approaches to uncertainty

**🎯 Focus Areas:**
- Bayes' theorem (foundation for Bayesian ML)
- Understanding uncertainty and confidence
- Distribution properties and when to use each

**💪 Practice:**
- Implement Naive Bayes classifier
- A/B testing with statistical significance
- Monte Carlo simulations
- **Project**: Spam detection using Bayesian methods

### 4. Core ML Concepts (Week 2, Days 1-3)
**Core Topics:**
- **Supervised Learning**: Classification, regression, evaluation metrics
- **Unsupervised Learning**: Clustering, association rules, outlier detection
- **Reinforcement Learning**: Agents, environments, rewards, policies
- **Semi-supervised**: Combining labeled and unlabeled data

**🎯 Focus Areas:**
- Understanding when to use each learning type
- Problem formulation skills
- Evaluation strategies for each type

**💪 Practice:**
- Classify different ML problems by type
- Design evaluation strategies for various scenarios
- Compare supervised vs unsupervised approaches
- **Project**: Customer segmentation analysis

### 5. Bias-Variance Tradeoff (Week 2, Days 4-5)
**Core Topics:**
- **Bias**: Underfitting, model assumptions, systematic errors
- **Variance**: Overfitting, model complexity, generalization
- **Noise**: Irreducible error, data quality issues
- **Model Selection**: Cross-validation, regularization

**🎯 Focus Areas:**
- Recognizing bias vs variance in real models
- Choosing appropriate model complexity
- Validation strategies

**💪 Practice:**
- Implement bias-variance decomposition
- Experiment with polynomial regression degrees
- Compare simple vs complex models
- **Project**: Model selection for house price prediction

### 6. Data Understanding (Week 2, Days 6-7)
**Core Topics:**
- **Data Types**: Numerical, categorical, ordinal, text, images
- **Data Quality**: Missing values, outliers, inconsistencies
- **Feature Engineering**: Creation, selection, transformation
- **Data Visualization**: Exploratory data analysis (EDA)

**🎯 Focus Areas:**
- Developing data intuition
- Identifying data quality issues
- Effective visualization techniques

**💪 Practice:**
- Perform comprehensive EDA on real datasets
- Handle different types of missing data
- Create meaningful visualizations
- **Project**: Complete data analysis of a business dataset

## 📚 Resources

### Books
- "Hands-On Machine Learning" by Aurélien Géron (Practical)
- "Pattern Recognition and Machine Learning" by Bishop (Theory)
- "The Elements of Statistical Learning" by Hastie (Advanced)

### Online Courses
- Andrew Ng's ML Course (Coursera)
- Fast.ai Practical Deep Learning
- CS229 Stanford ML Course

### Practice Platforms
- Kaggle Learn (Free micro-courses)
- Coursera/edX specializations
- DataCamp/Codecademy

## 🎯 This Week's Goals

**Week 1: Mathematical Foundation**
- [ ] Master vector/matrix operations in NumPy
- [ ] Implement gradient descent from scratch
- [ ] Understand probability distributions
- [ ] Complete bias-variance notebook

**Week 2: ML Concepts**
- [ ] Build first classification model
- [ ] Perform comprehensive data analysis
- [ ] Understand evaluation metrics
- [ ] Complete capstone project

## 💡 Learning Strategies

### For Senior Engineers:
1. **Connect to Software Engineering**:
   - Think of ML as pattern recognition algorithms
   - Linear algebra = data transformations
   - Optimization = finding best parameters
   - Statistics = measuring algorithm performance

2. **Hands-on First**:
   - Code concepts immediately after learning
   - Don't get stuck on perfect mathematical understanding
   - Build intuition through experimentation

3. **Focus on Application**:
   - Always ask "how is this used in practice?"
   - Connect math concepts to real ML algorithms
   - Prioritize concepts used in modern ML

## 🏋️ Practice Exercises

### Daily Coding Challenges:
1. **Day 1**: Implement vector operations without NumPy
2. **Day 2**: Build matrix multiplication from scratch
3. **Day 3**: Create gradient descent optimizer
4. **Day 4**: Implement linear regression manually
5. **Day 5**: Build Naive Bayes classifier
6. **Day 6**: Perform EDA on Titanic dataset
7. **Day 7**: Compare multiple models on same data

### Weekly Projects:
- **Week 1**: Mathematical toolkit implementation
- **Week 2**: End-to-end ML project (data → model → evaluation)

## 🎮 Gamification

### Achievement Badges:
- 🧮 **Math Master**: Complete all linear algebra exercises
- 📊 **Data Detective**: Find 5 insights in a dataset
- 🎯 **Model Builder**: Train your first classifier
- 📈 **Optimizer**: Implement gradient descent
- 🔍 **Evaluator**: Master precision, recall, F1-score

## 📋 Prerequisites Check

Before moving to module 02, ensure you can:
- [ ] Perform basic matrix operations
- [ ] Understand probability distributions
- [ ] Explain bias-variance tradeoff
- [ ] Identify supervised vs unsupervised problems
- [ ] Set up Python ML environment

## 🚀 Next Module Preview

Module 02 will cover the Python ML stack: NumPy, Pandas, Matplotlib, and your first ML model with scikit-learn!
