{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculus and Optimization Lab\n",
    "\n",
    "In this lab, we will explore key concepts of calculus and optimization that are essential for understanding machine learning algorithms. We will cover derivatives, gradients, and optimization techniques such as gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define a simple quadratic function\n",
    "def f(x):\n",
    "    return x**2 + 4*x + 4\n",
    "\n",
    "# Generate x values\n",
    "x = np.linspace(-10, 0, 100)\n",
    "\n",
    "# Plot the function\n",
    "plt.plot(x, f(x), label='f(x) = x^2 + 4x + 4')\n",
    "plt.title('Quadratic Function')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.axhline(0, color='black', lw=0.5, ls='--')\n",
    "plt.axvline(0, color='black', lw=0.5, ls='--')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derivatives and Gradients\n",
    "\n",
    "Let's compute the derivative of the function and visualize it. The derivative represents the slope of the function at any point, which is crucial for optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the derivative of the function\n",
    "def df(x):\n",
    "    return 2*x + 4\n",
    "\n",
    "# Plot the function and its derivative\n",
    "plt.plot(x, f(x), label='f(x)')\n",
    "plt.plot(x, df(x), label=\"f'(x)\", linestyle='--')\n",
    "plt.title('Function and its Derivative')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Value')\n",
    "plt.axhline(0, color='black', lw=0.5, ls='--')\n",
    "plt.axvline(0, color='black', lw=0.5, ls='--')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent\n",
    "\n",
    "Now, let's implement a simple gradient descent algorithm to find the minimum of the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Gradient Descent Implementation\n",
    "def gradient_descent(starting_point, learning_rate, num_iterations):\n",
    "    x = starting_point\n",
    "    for _ in range(num_iterations):\n",
    "        x -= learning_rate * df(x)\n",
    "    return x\n",
    "\n",
    "# Run gradient descent\n",
    "minimum = gradient_descent(starting_point=-5, learning_rate=0.1, num_iterations=50)\n",
    "print(f'The minimum value found at x = {minimum}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "In this lab, we explored the fundamentals of calculus and optimization. We visualized a quadratic function, computed its derivative, and implemented a simple gradient descent algorithm to find its minimum. Understanding these concepts is crucial for developing and optimizing machine learning models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}