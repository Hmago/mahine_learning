{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6ab625c",
   "metadata": {},
   "source": [
    "# üéØ Probability and Statistics Fundamentals for Machine Learning\n",
    "\n",
    "**A comprehensive interactive guide covering probability basics, distributions, statistical inference, and Bayesian methods**\n",
    "\n",
    "## üìã Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "- Master conditional probability and Bayes' theorem\n",
    "- Understand key probability distributions and their ML applications\n",
    "- Apply statistical inference for hypothesis testing and confidence intervals\n",
    "- Compare Bayesian vs Frequentist approaches\n",
    "- Implement A/B testing with statistical significance\n",
    "- Build a spam detection system using Bayesian methods\n",
    "\n",
    "## üéØ Core Topics Covered\n",
    "\n",
    "1. **Probability Basics**: Conditional probability, Bayes' theorem\n",
    "2. **Distributions**: Normal, binomial, Poisson, exponential\n",
    "3. **Statistical Inference**: Hypothesis testing, confidence intervals\n",
    "4. **Bayesian vs Frequentist**: Different approaches to uncertainty\n",
    "\n",
    "## üí™ Practice Projects\n",
    "\n",
    "1. **A/B Testing with Statistical Significance**\n",
    "2. **Spam Detection using Bayesian Methods**\n",
    "\n",
    "---\n",
    "\n",
    "Let's begin our journey into the mathematical foundations of machine learning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8f263e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential libraries for probability and statistics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.optimize import minimize\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better visualizations\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "np.random.seed(42)\n",
    "\n",
    "# Configuration for better plots\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")\n",
    "print(\"üìä Ready for probability and statistics exploration!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ff47e4",
   "metadata": {},
   "source": [
    "# 1. üéØ Probability Basics: The Foundation of ML\n",
    "\n",
    "## 1.1 Understanding Conditional Probability\n",
    "\n",
    "**Definition**: P(A|B) = P(A ‚à© B) / P(B)\n",
    "\n",
    "Conditional probability is the likelihood of event A occurring given that event B has occurred. This is **fundamental** to machine learning because:\n",
    "\n",
    "- **Feature relationships**: How does one feature affect predictions given another?\n",
    "- **Bayesian inference**: How do we update beliefs with new evidence?\n",
    "- **Classification**: What's the probability of a class given observed features?\n",
    "\n",
    "### üîç Real-World Example: Email Classification\n",
    "\n",
    "Let's explore a practical scenario where conditional probability is crucial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0352672a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Email Classification Example\n",
    "# Let's solve a real conditional probability problem\n",
    "\n",
    "# Given information\n",
    "P_spam = 0.4          # 40% of emails are spam\n",
    "P_legitimate = 0.6    # 60% of emails are legitimate\n",
    "P_urgent_given_spam = 0.8     # 80% of spam contains \"urgent\"\n",
    "P_urgent_given_legit = 0.05   # 5% of legitimate emails contain \"urgent\"\n",
    "\n",
    "print(\"üìß EMAIL CLASSIFICATION PROBLEM\")\n",
    "print(\"=\"*50)\n",
    "print(f\"P(Spam) = {P_spam}\")\n",
    "print(f\"P(Legitimate) = {P_legitimate}\")\n",
    "print(f\"P('urgent'|Spam) = {P_urgent_given_spam}\")\n",
    "print(f\"P('urgent'|Legitimate) = {P_urgent_given_legit}\")\n",
    "\n",
    "# Question 1: What's P(contains \"urgent\")?\n",
    "# Using law of total probability: P(U) = P(U|S)P(S) + P(U|L)P(L)\n",
    "P_urgent = P_urgent_given_spam * P_spam + P_urgent_given_legit * P_legitimate\n",
    "\n",
    "print(f\"\\nüéØ SOLUTIONS:\")\n",
    "print(f\"1. P(contains 'urgent') = {P_urgent:.3f}\")\n",
    "\n",
    "# Question 2: If email contains \"urgent\", what's P(Spam)?\n",
    "# Using Bayes' theorem: P(S|U) = P(U|S)P(S) / P(U)\n",
    "P_spam_given_urgent = (P_urgent_given_spam * P_spam) / P_urgent\n",
    "\n",
    "print(f\"2. P(Spam | contains 'urgent') = {P_spam_given_urgent:.3f}\")\n",
    "\n",
    "# Question 3: If email doesn't contain \"urgent\", what's P(Legitimate)?\n",
    "P_not_urgent = 1 - P_urgent\n",
    "P_not_urgent_given_legit = 1 - P_urgent_given_legit\n",
    "P_legit_given_not_urgent = (P_not_urgent_given_legit * P_legitimate) / P_not_urgent\n",
    "\n",
    "print(f\"3. P(Legitimate | doesn't contain 'urgent') = {P_legit_given_not_urgent:.3f}\")\n",
    "\n",
    "# Visualization\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Prior vs Posterior probabilities\n",
    "categories = ['Prior P(Spam)', 'Posterior P(Spam|urgent)']\n",
    "probabilities = [P_spam, P_spam_given_urgent]\n",
    "\n",
    "ax1.bar(categories, probabilities, color=['lightcoral', 'darkred'], alpha=0.7)\n",
    "ax1.set_ylabel('Probability')\n",
    "ax1.set_title('How Evidence Updates Our Beliefs')\n",
    "ax1.set_ylim(0, 1)\n",
    "for i, prob in enumerate(probabilities):\n",
    "    ax1.text(i, prob + 0.02, f'{prob:.3f}', ha='center', fontweight='bold')\n",
    "\n",
    "# Breakdown of urgent emails\n",
    "urgent_spam = P_urgent_given_spam * P_spam\n",
    "urgent_legit = P_urgent_given_legit * P_legitimate\n",
    "\n",
    "labels = ['Urgent Spam', 'Urgent Legitimate']\n",
    "sizes = [urgent_spam, urgent_legit]\n",
    "colors = ['darkred', 'lightblue']\n",
    "\n",
    "ax2.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90)\n",
    "ax2.set_title('Composition of \"Urgent\" Emails')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüí° KEY INSIGHT:\")\n",
    "print(f\"Even though 80% of spam contains 'urgent', if an email contains 'urgent',\")\n",
    "print(f\"there's only a {P_spam_given_urgent:.1%} chance it's spam!\")\n",
    "print(f\"This shows the importance of base rates (prior probabilities).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cec5f1",
   "metadata": {},
   "source": [
    "## 1.2 üéØ Bayes' Theorem: Foundation of Bayesian ML\n",
    "\n",
    "**Bayes' theorem is THE most important concept in machine learning!**\n",
    "\n",
    "### The Formula\n",
    "\n",
    "```\n",
    "P(H|E) = P(E|H) √ó P(H) / P(E)\n",
    "```\n",
    "\n",
    "Where:\n",
    "- **P(H|E)**: **Posterior** - What we want to find (probability of hypothesis given evidence)\n",
    "- **P(E|H)**: **Likelihood** - How likely is the evidence given our hypothesis?\n",
    "- **P(H)**: **Prior** - Our initial belief before seeing evidence\n",
    "- **P(E)**: **Marginal Likelihood** - Normalizing constant (often ignored in ML)\n",
    "\n",
    "### Why It's Crucial for ML\n",
    "\n",
    "1. **Naive Bayes Classifier**: Direct application\n",
    "2. **Bayesian Networks**: Model complex dependencies  \n",
    "3. **Parameter Estimation**: Update model parameters with new data\n",
    "4. **Uncertainty Quantification**: Measure confidence in predictions\n",
    "5. **Active Learning**: Choose most informative data points\n",
    "\n",
    "### üè• Medical Diagnosis Example\n",
    "\n",
    "Let's see how Bayes' theorem can be counterintuitive but crucial for decision-making."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad0e0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Medical Diagnosis: The Classic Bayes' Theorem Problem\n",
    "print(\"üè• MEDICAL DIAGNOSIS WITH BAYES' THEOREM\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Scenario: Testing for a rare disease\n",
    "disease_prevalence = 0.01    # 1% of population has the disease\n",
    "test_sensitivity = 0.95      # 95% of sick people test positive\n",
    "test_specificity = 0.95      # 95% of healthy people test negative\n",
    "\n",
    "print(f\"Disease prevalence: {disease_prevalence:.1%}\")\n",
    "print(f\"Test sensitivity (True Positive Rate): {test_sensitivity:.1%}\")  \n",
    "print(f\"Test specificity (True Negative Rate): {test_specificity:.1%}\")\n",
    "\n",
    "# Calculate using Bayes' theorem\n",
    "# P(Disease|Positive) = P(Positive|Disease) √ó P(Disease) / P(Positive)\n",
    "\n",
    "# First, find P(Positive) using law of total probability\n",
    "P_positive_given_disease = test_sensitivity\n",
    "P_positive_given_healthy = 1 - test_specificity\n",
    "P_disease = disease_prevalence\n",
    "P_healthy = 1 - disease_prevalence\n",
    "\n",
    "P_positive = P_positive_given_disease * P_disease + P_positive_given_healthy * P_healthy\n",
    "\n",
    "# Now apply Bayes' theorem\n",
    "P_disease_given_positive = (P_positive_given_disease * P_disease) / P_positive\n",
    "\n",
    "print(f\"\\nüéØ THE SHOCKING RESULT:\")\n",
    "print(f\"P(Disease | Positive Test) = {P_disease_given_positive:.3f} or {P_disease_given_positive:.1%}\")\n",
    "\n",
    "print(f\"\\nüí° INTERPRETATION:\")\n",
    "print(f\"Even with a 95% accurate test, if you test positive,\")\n",
    "print(f\"there's only a {P_disease_given_positive:.1%} chance you have the disease!\")\n",
    "print(f\"This is because the disease is rare (base rate fallacy).\")\n",
    "\n",
    "# Create comprehensive visualization\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# 1. Population breakdown\n",
    "population_data = {\n",
    "    'Diseased & Test +': P_positive_given_disease * P_disease,\n",
    "    'Diseased & Test -': (1-P_positive_given_disease) * P_disease,\n",
    "    'Healthy & Test +': P_positive_given_healthy * P_healthy,\n",
    "    'Healthy & Test -': (1-P_positive_given_healthy) * P_healthy\n",
    "}\n",
    "\n",
    "bars = ax1.bar(range(len(population_data)), list(population_data.values()), \n",
    "               color=['darkred', 'lightcoral', 'orange', 'lightgreen'])\n",
    "ax1.set_xticks(range(len(population_data)))\n",
    "ax1.set_xticklabels(list(population_data.keys()), rotation=45, ha='right')\n",
    "ax1.set_ylabel('Probability')\n",
    "ax1.set_title('Population Breakdown (out of 1.0)')\n",
    "for i, (key, value) in enumerate(population_data.items()):\n",
    "    ax1.text(i, value + 0.001, f'{value:.4f}', ha='center', fontsize=10)\n",
    "\n",
    "# 2. Among positive tests\n",
    "positive_breakdown = {\n",
    "    'True Positives': P_positive_given_disease * P_disease,\n",
    "    'False Positives': P_positive_given_healthy * P_healthy\n",
    "}\n",
    "\n",
    "ax2.pie(positive_breakdown.values(), labels=positive_breakdown.keys(), \n",
    "        autopct='%1.1f%%', colors=['darkred', 'orange'])\n",
    "ax2.set_title('Breakdown of Positive Tests')\n",
    "\n",
    "# 3. Prior vs Posterior\n",
    "probs = ['Prior P(Disease)', 'Posterior P(Disease|+)']\n",
    "values = [P_disease, P_disease_given_positive]\n",
    "bars = ax3.bar(probs, values, color=['lightblue', 'darkred'], alpha=0.7)\n",
    "ax3.set_ylabel('Probability')\n",
    "ax3.set_title('Prior vs Posterior Probability')\n",
    "ax3.set_ylim(0, max(values) * 1.2)\n",
    "for i, val in enumerate(values):\n",
    "    ax3.text(i, val + max(values)*0.02, f'{val:.3f}', ha='center', fontweight='bold')\n",
    "\n",
    "# 4. Effect of prevalence on posterior probability\n",
    "prevalences = np.logspace(-4, -1, 50)  # From 0.01% to 10%\n",
    "posteriors = []\n",
    "\n",
    "for prev in prevalences:\n",
    "    p_pos = test_sensitivity * prev + (1-test_specificity) * (1-prev)\n",
    "    posterior = (test_sensitivity * prev) / p_pos\n",
    "    posteriors.append(posterior)\n",
    "\n",
    "ax4.semilogx(prevalences * 100, np.array(posteriors) * 100, 'b-', linewidth=2)\n",
    "ax4.axhline(y=P_disease_given_positive * 100, color='r', linestyle='--', \n",
    "            label=f'Our case: {P_disease_given_positive:.1%}')\n",
    "ax4.axvline(x=disease_prevalence * 100, color='r', linestyle='--', alpha=0.5)\n",
    "ax4.set_xlabel('Disease Prevalence (%)')\n",
    "ax4.set_ylabel('P(Disease | Positive Test) (%)')\n",
    "ax4.set_title('How Prevalence Affects Positive Predictive Value')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "ax4.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüîç KEY LESSONS:\")\n",
    "print(f\"1. Base rates matter enormously in predictions\")\n",
    "print(f\"2. High test accuracy ‚â† high positive predictive value for rare events\")\n",
    "print(f\"3. Always consider prior probabilities in ML models\")\n",
    "print(f\"4. This is why feature selection and domain knowledge are crucial\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95805d8",
   "metadata": {},
   "source": [
    "# 2. üìä Key Probability Distributions for ML\n",
    "\n",
    "Understanding distributions is crucial because:\n",
    "- **Data modeling**: Choose the right distribution for your data\n",
    "- **Algorithm assumptions**: Many ML algorithms assume specific distributions\n",
    "- **Feature engineering**: Transform data to meet distributional assumptions\n",
    "- **Uncertainty quantification**: Model different types of uncertainty\n",
    "\n",
    "## 2.1 üîî Normal Distribution: The King of Statistics\n",
    "\n",
    "**Why it's everywhere in ML:**\n",
    "- Central Limit Theorem: Sample means approach normal\n",
    "- Many algorithms assume normality (Linear Regression, LDA, etc.)\n",
    "- Optimization: Gaussian priors in Bayesian methods\n",
    "- Feature scaling: StandardScaler assumes normal distribution\n",
    "\n",
    "**Key Properties:**\n",
    "- **PDF**: f(x) = (1/‚àö(2œÄœÉ¬≤)) √ó e^(-(x-Œº)¬≤/(2œÉ¬≤))\n",
    "- **Parameters**: Œº (mean), œÉ¬≤ (variance)  \n",
    "- **68-95-99.7 Rule**: ~68% within 1œÉ, ~95% within 2œÉ, ~99.7% within 3œÉ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2216808a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal Distribution: Comprehensive Analysis\n",
    "print(\"üîî NORMAL DISTRIBUTION IN ML\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Example: Student Heights Dataset\n",
    "mu_height = 170  # mean height in cm\n",
    "sigma_height = 10  # standard deviation\n",
    "\n",
    "print(f\"Student Heights: Œº = {mu_height} cm, œÉ = {sigma_height} cm\")\n",
    "\n",
    "# Generate sample data\n",
    "np.random.seed(42)\n",
    "heights = np.random.normal(mu_height, sigma_height, 1000)\n",
    "\n",
    "# Key questions and calculations\n",
    "print(f\"\\nüéØ KEY CALCULATIONS:\")\n",
    "\n",
    "# 1. Percentage between 160-180 cm\n",
    "prob_160_180 = stats.norm.cdf(180, mu_height, sigma_height) - stats.norm.cdf(160, mu_height, sigma_height)\n",
    "print(f\"1. P(160 < Height < 180) = {prob_160_180:.3f} or {prob_160_180:.1%}\")\n",
    "\n",
    "# 2. 90th percentile\n",
    "height_90th = stats.norm.ppf(0.9, mu_height, sigma_height)\n",
    "print(f\"2. 90th percentile height = {height_90th:.1f} cm\")\n",
    "\n",
    "# 3. Sample mean distribution (n=25)\n",
    "n_sample = 25\n",
    "sigma_sample_mean = sigma_height / np.sqrt(n_sample)\n",
    "prob_sample_mean_above_172 = 1 - stats.norm.cdf(172, mu_height, sigma_sample_mean)\n",
    "print(f\"3. P(Sample mean > 172 | n=25) = {prob_sample_mean_above_172:.3f}\")\n",
    "\n",
    "# Comprehensive visualization\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. PDF with key regions\n",
    "x = np.linspace(140, 200, 1000)\n",
    "pdf = stats.norm.pdf(x, mu_height, sigma_height)\n",
    "\n",
    "ax1.plot(x, pdf, 'b-', linewidth=2, label='PDF')\n",
    "ax1.fill_between(x, pdf, alpha=0.3, color='lightblue')\n",
    "\n",
    "# Highlight 68-95-99.7 rule\n",
    "ax1.axvline(mu_height, color='red', linestyle='--', label='Mean')\n",
    "ax1.axvline(mu_height + sigma_height, color='orange', linestyle='--', alpha=0.7, label='¬±1œÉ')\n",
    "ax1.axvline(mu_height - sigma_height, color='orange', linestyle='--', alpha=0.7)\n",
    "ax1.axvline(mu_height + 2*sigma_height, color='green', linestyle='--', alpha=0.7, label='¬±2œÉ')\n",
    "ax1.axvline(mu_height - 2*sigma_height, color='green', linestyle='--', alpha=0.7)\n",
    "\n",
    "ax1.set_xlabel('Height (cm)')\n",
    "ax1.set_ylabel('Probability Density')\n",
    "ax1.set_title('Normal Distribution: 68-95-99.7 Rule')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Sample data histogram vs theoretical\n",
    "ax2.hist(heights, bins=30, density=True, alpha=0.7, color='lightcoral', label='Sample Data')\n",
    "ax2.plot(x, pdf, 'b-', linewidth=2, label='Theoretical PDF')\n",
    "ax2.set_xlabel('Height (cm)')\n",
    "ax2.set_ylabel('Density')\n",
    "ax2.set_title('Sample vs Theoretical Distribution')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. CDF for probability calculations\n",
    "cdf = stats.norm.cdf(x, mu_height, sigma_height)\n",
    "ax3.plot(x, cdf, 'g-', linewidth=2)\n",
    "\n",
    "# Highlight the 160-180 range\n",
    "mask = (x >= 160) & (x <= 180)\n",
    "ax3.fill_between(x[mask], 0, cdf[mask], alpha=0.3, color='yellow', label='P(160 < X < 180)')\n",
    "\n",
    "ax3.axhline(y=0.9, color='red', linestyle='--', alpha=0.7)\n",
    "ax3.axvline(x=height_90th, color='red', linestyle='--', alpha=0.7, label=f'90th percentile: {height_90th:.1f}')\n",
    "\n",
    "ax3.set_xlabel('Height (cm)')\n",
    "ax3.set_ylabel('Cumulative Probability')\n",
    "ax3.set_title('Cumulative Distribution Function (CDF)')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Sampling distribution of the mean\n",
    "sample_sizes = [1, 5, 10, 25, 50]\n",
    "x_sample = np.linspace(160, 180, 1000)\n",
    "\n",
    "for n in sample_sizes:\n",
    "    sigma_n = sigma_height / np.sqrt(n)\n",
    "    pdf_n = stats.norm.pdf(x_sample, mu_height, sigma_n)\n",
    "    ax4.plot(x_sample, pdf_n, label=f'n={n}', linewidth=2)\n",
    "\n",
    "ax4.set_xlabel('Sample Mean Height (cm)')\n",
    "ax4.set_ylabel('Probability Density')\n",
    "ax4.set_title('Central Limit Theorem: Distribution of Sample Mean')\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ML Applications demonstration\n",
    "print(f\"\\nü§ñ ML APPLICATIONS:\")\n",
    "print(f\"1. Feature Scaling: StandardScaler transforms to N(0,1)\")\n",
    "print(f\"2. Linear Regression: Assumes normal residuals\")\n",
    "print(f\"3. Gaussian Naive Bayes: Models P(feature|class) as normal\")\n",
    "print(f\"4. PCA: Projects data onto normal distributions\")\n",
    "\n",
    "# Feature scaling example\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "heights_scaled = scaler.fit_transform(heights.reshape(-1, 1)).flatten()\n",
    "\n",
    "print(f\"\\nüìè FEATURE SCALING EXAMPLE:\")\n",
    "print(f\"Original: Œº = {np.mean(heights):.2f}, œÉ = {np.std(heights):.2f}\")\n",
    "print(f\"Scaled:   Œº = {np.mean(heights_scaled):.2f}, œÉ = {np.std(heights_scaled):.2f}\")\n",
    "\n",
    "# Practical tip: Testing for normality\n",
    "from scipy.stats import shapiro, normaltest\n",
    "shapiro_stat, shapiro_p = shapiro(heights[:100])  # Shapiro-Wilk test (small samples)\n",
    "dagostino_stat, dagostino_p = normaltest(heights)  # D'Agostino test (larger samples)\n",
    "\n",
    "print(f\"\\nüß™ NORMALITY TESTS:\")\n",
    "print(f\"Shapiro-Wilk p-value: {shapiro_p:.4f}\")\n",
    "print(f\"D'Agostino p-value: {dagostino_p:.4f}\")\n",
    "print(f\"If p > 0.05, we can assume normality\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c43baa5",
   "metadata": {},
   "source": [
    "## 2.2 üé≤ Binomial Distribution: For Binary Outcomes\n",
    "\n",
    "**Perfect for A/B testing and classification problems!**\n",
    "\n",
    "**Key Properties:**\n",
    "- **PMF**: P(X = k) = C(n,k) √ó p^k √ó (1-p)^(n-k)\n",
    "- **Parameters**: n (number of trials), p (success probability)\n",
    "- **Mean**: Œº = np\n",
    "- **Variance**: œÉ¬≤ = np(1-p)\n",
    "\n",
    "**When to Use:**\n",
    "- Fixed number of independent trials\n",
    "- Each trial has only two outcomes (success/failure)\n",
    "- Probability of success remains constant\n",
    "- Trials are independent\n",
    "\n",
    "**ML Applications:**\n",
    "- A/B testing analysis\n",
    "- Classification performance metrics\n",
    "- Bernoulli features (binary variables)\n",
    "- Confidence intervals for proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0939b0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binomial Distribution: A/B Testing Example\n",
    "print(\"üé≤ BINOMIAL DISTRIBUTION IN A/B TESTING\")\n",
    "print(\"=\"*45)\n",
    "\n",
    "# A/B Testing Scenario\n",
    "n_control = 1000      # Control group size\n",
    "n_treatment = 1000    # Treatment group size\n",
    "conversions_control = 50    # Control conversions\n",
    "conversions_treatment = 65  # Treatment conversions\n",
    "\n",
    "p_control = conversions_control / n_control\n",
    "p_treatment = conversions_treatment / n_treatment\n",
    "\n",
    "print(f\"Control Group: {conversions_control}/{n_control} = {p_control:.1%} conversion rate\")\n",
    "print(f\"Treatment Group: {conversions_treatment}/{n_treatment} = {p_treatment:.1%} conversion rate\")\n",
    "print(f\"Observed Improvement: {((p_treatment - p_control)/p_control):.1%}\")\n",
    "\n",
    "# Statistical Analysis\n",
    "print(f\"\\nüìä STATISTICAL ANALYSIS:\")\n",
    "\n",
    "# 1. Confidence intervals for each group\n",
    "alpha = 0.05  # 95% confidence\n",
    "z_critical = stats.norm.ppf(1 - alpha/2)\n",
    "\n",
    "# Control group CI\n",
    "se_control = np.sqrt(p_control * (1 - p_control) / n_control)\n",
    "ci_control_lower = p_control - z_critical * se_control\n",
    "ci_control_upper = p_control + z_critical * se_control\n",
    "\n",
    "# Treatment group CI  \n",
    "se_treatment = np.sqrt(p_treatment * (1 - p_treatment) / n_treatment)\n",
    "ci_treatment_lower = p_treatment - z_critical * se_treatment\n",
    "ci_treatment_upper = p_treatment + z_critical * se_treatment\n",
    "\n",
    "print(f\"Control 95% CI: [{ci_control_lower:.3f}, {ci_control_upper:.3f}]\")\n",
    "print(f\"Treatment 95% CI: [{ci_treatment_lower:.3f}, {ci_treatment_upper:.3f}]\")\n",
    "\n",
    "# 2. Two-proportion z-test\n",
    "pooled_p = (conversions_control + conversions_treatment) / (n_control + n_treatment)\n",
    "se_diff = np.sqrt(pooled_p * (1 - pooled_p) * (1/n_control + 1/n_treatment))\n",
    "z_stat = (p_treatment - p_control) / se_diff\n",
    "p_value = 2 * (1 - stats.norm.cdf(abs(z_stat)))\n",
    "\n",
    "print(f\"\\nüß™ HYPOTHESIS TEST:\")\n",
    "print(f\"H‚ÇÄ: p_treatment = p_control\")\n",
    "print(f\"H‚ÇÅ: p_treatment ‚â† p_control\")\n",
    "print(f\"Z-statistic: {z_stat:.3f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "print(f\"Result: {'Significant' if p_value < 0.05 else 'Not significant'} at Œ± = 0.05\")\n",
    "\n",
    "# 3. Power analysis - what sample size would we need?\n",
    "from statsmodels.stats.power import zt_ind_solve_power\n",
    "effect_size = (p_treatment - p_control) / np.sqrt(pooled_p * (1 - pooled_p))\n",
    "required_n = zt_ind_solve_power(effect_size, power=0.8, alpha=0.05)\n",
    "print(f\"\\n‚ö° POWER ANALYSIS:\")\n",
    "print(f\"To detect this effect with 80% power, we'd need n = {required_n:.0f} per group\")\n",
    "\n",
    "# Comprehensive Visualization\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Binomial PMF comparison\n",
    "k_values = np.arange(0, 101)\n",
    "pmf_control = stats.binom.pmf(k_values, n_control, p_control)\n",
    "pmf_treatment = stats.binom.pmf(k_values, n_treatment, p_treatment)\n",
    "\n",
    "ax1.plot(k_values, pmf_control, 'b-', alpha=0.7, label=f'Control (p={p_control:.3f})')\n",
    "ax1.plot(k_values, pmf_treatment, 'r-', alpha=0.7, label=f'Treatment (p={p_treatment:.3f})')\n",
    "ax1.axvline(conversions_control, color='blue', linestyle='--', alpha=0.7, label='Observed Control')\n",
    "ax1.axvline(conversions_treatment, color='red', linestyle='--', alpha=0.7, label='Observed Treatment')\n",
    "ax1.set_xlabel('Number of Conversions')\n",
    "ax1.set_ylabel('Probability')\n",
    "ax1.set_title('Binomial Distributions: Control vs Treatment')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Confidence intervals visualization\n",
    "groups = ['Control', 'Treatment']\n",
    "rates = [p_control, p_treatment]\n",
    "lower_bounds = [ci_control_lower, ci_treatment_lower]\n",
    "upper_bounds = [ci_control_upper, ci_treatment_upper]\n",
    "\n",
    "x_pos = np.arange(len(groups))\n",
    "ax2.bar(x_pos, rates, yerr=[np.array(rates) - np.array(lower_bounds), \n",
    "                            np.array(upper_bounds) - np.array(rates)], \n",
    "        capsize=10, color=['blue', 'red'], alpha=0.7)\n",
    "ax2.set_xlabel('Group')\n",
    "ax2.set_ylabel('Conversion Rate')\n",
    "ax2.set_title('95% Confidence Intervals')\n",
    "ax2.set_xticks(x_pos)\n",
    "ax2.set_xticklabels(groups)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Probability of observing results under null hypothesis\n",
    "# If true rates were equal, what's P(observing ‚â• 65 conversions in treatment)?\n",
    "prob_65_or_more_under_null = 1 - stats.binom.cdf(64, n_treatment, p_control)\n",
    "\n",
    "k_null = np.arange(35, 85)\n",
    "pmf_null = stats.binom.pmf(k_null, n_treatment, p_control)\n",
    "ax3.plot(k_null, pmf_null, 'g-', linewidth=2, label=f'Under H‚ÇÄ (p={p_control:.3f})')\n",
    "ax3.fill_between(k_null[k_null >= conversions_treatment], \n",
    "                 pmf_null[k_null >= conversions_treatment], \n",
    "                 alpha=0.3, color='red', label=f'P(X‚â•{conversions_treatment}) = {prob_65_or_more_under_null:.4f}')\n",
    "ax3.axvline(conversions_treatment, color='red', linestyle='--', label='Observed')\n",
    "ax3.set_xlabel('Number of Conversions')\n",
    "ax3.set_ylabel('Probability')\n",
    "ax3.set_title('Probability Under Null Hypothesis')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Normal approximation validation\n",
    "# Binomial approaches normal when np > 5 and n(1-p) > 5\n",
    "normal_control = stats.norm(n_control * p_control, np.sqrt(n_control * p_control * (1 - p_control)))\n",
    "normal_treatment = stats.norm(n_treatment * p_treatment, np.sqrt(n_treatment * p_treatment * (1 - p_treatment)))\n",
    "\n",
    "x_norm = np.arange(30, 90)\n",
    "ax4.plot(x_norm, stats.binom.pmf(x_norm, n_control, p_control), 'bo-', alpha=0.5, label='Binomial Control')\n",
    "ax4.plot(x_norm, normal_control.pdf(x_norm), 'b-', linewidth=2, label='Normal Approx Control')\n",
    "ax4.plot(x_norm, stats.binom.pmf(x_norm, n_treatment, p_treatment), 'ro-', alpha=0.5, label='Binomial Treatment')\n",
    "ax4.plot(x_norm, normal_treatment.pdf(x_norm), 'r-', linewidth=2, label='Normal Approx Treatment')\n",
    "ax4.set_xlabel('Number of Conversions')\n",
    "ax4.set_ylabel('Probability/Density')\n",
    "ax4.set_title('Normal Approximation to Binomial')\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Practical ML Applications\n",
    "print(f\"\\nü§ñ ML APPLICATIONS:\")\n",
    "print(f\"1. Classification accuracy: Binomial(n_samples, true_accuracy)\")\n",
    "print(f\"2. Cross-validation: Each fold is a Bernoulli trial\")\n",
    "print(f\"3. Feature selection: Binary features follow Bernoulli\")\n",
    "print(f\"4. Online learning: Update beliefs with each binary outcome\")\n",
    "\n",
    "# Simulation: What if we continued the experiment?\n",
    "print(f\"\\nüîÆ SIMULATION: Continuing the Experiment\")\n",
    "additional_samples = 500\n",
    "new_control = np.random.binomial(additional_samples, p_control)\n",
    "new_treatment = np.random.binomial(additional_samples, p_treatment)\n",
    "\n",
    "total_control = conversions_control + new_control\n",
    "total_treatment = conversions_treatment + new_treatment\n",
    "total_n = n_control + additional_samples\n",
    "\n",
    "new_p_control = total_control / total_n\n",
    "new_p_treatment = total_treatment / total_n\n",
    "\n",
    "print(f\"After {additional_samples} more samples each:\")\n",
    "print(f\"Control: {new_p_control:.3f} vs Treatment: {new_p_treatment:.3f}\")\n",
    "print(f\"This demonstrates how more data affects our confidence!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6de44df",
   "metadata": {},
   "source": [
    "## 2.3 ‚ö° Poisson Distribution: Modeling Count Data\n",
    "\n",
    "**Perfect for modeling rare events and count data!**\n",
    "\n",
    "**Key Properties:**\n",
    "- **PMF**: P(X = k) = (Œª^k √ó e^(-Œª)) / k!\n",
    "- **Parameter**: Œª (rate parameter)\n",
    "- **Mean**: Œº = Œª, **Variance**: œÉ¬≤ = Œª\n",
    "\n",
    "**When to Use:**\n",
    "- Count events in fixed time/space intervals\n",
    "- Events are rare and independent\n",
    "- Rate is approximately constant\n",
    "- Examples: Website clicks, customer arrivals, defects\n",
    "\n",
    "## 2.4 ‚è±Ô∏è Exponential Distribution: Time Between Events\n",
    "\n",
    "**Perfect for modeling waiting times and reliability!**\n",
    "\n",
    "**Key Properties:**\n",
    "- **PDF**: f(x) = Œªe^(-Œªx) for x ‚â• 0\n",
    "- **Parameter**: Œª (rate parameter)\n",
    "- **Mean**: Œº = 1/Œª, **Variance**: œÉ¬≤ = 1/Œª¬≤\n",
    "- **Memoryless property**: P(X > s+t | X > s) = P(X > t)\n",
    "\n",
    "**When to Use:**\n",
    "- Time until next event\n",
    "- Component lifetimes\n",
    "- Service times in queues\n",
    "- Survival analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d543da9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poisson & Exponential Distributions: Server Analytics Example\n",
    "print(\"‚ö° POISSON & EXPONENTIAL DISTRIBUTIONS\")\n",
    "print(\"=\"*45)\n",
    "\n",
    "# Scenario: Web server analytics\n",
    "lambda_requests = 12  # Average 12 requests per minute\n",
    "print(f\"Server receives an average of {lambda_requests} requests per minute\")\n",
    "\n",
    "# Poisson Analysis: Count of events\n",
    "print(f\"\\nüìä POISSON ANALYSIS (Count of Events):\")\n",
    "\n",
    "# Key questions\n",
    "prob_exactly_15 = stats.poisson.pmf(15, lambda_requests)\n",
    "prob_more_than_20 = 1 - stats.poisson.cdf(20, lambda_requests)\n",
    "capacity_99_percent = stats.poisson.ppf(0.99, lambda_requests)\n",
    "\n",
    "print(f\"1. P(exactly 15 requests in 1 minute) = {prob_exactly_15:.4f}\")\n",
    "print(f\"2. P(more than 20 requests in 1 minute) = {prob_more_than_20:.4f}\")\n",
    "print(f\"3. Server capacity for 99% coverage: {capacity_99_percent:.0f} requests/minute\")\n",
    "\n",
    "# 5-minute window analysis\n",
    "lambda_5min = lambda_requests * 5\n",
    "print(f\"\\nIn a 5-minute window:\")\n",
    "print(f\"Expected requests: {lambda_5min}\")\n",
    "print(f\"Variance: {lambda_5min}\")\n",
    "print(f\"Standard deviation: {np.sqrt(lambda_5min):.2f}\")\n",
    "\n",
    "# Exponential Analysis: Time between events\n",
    "print(f\"\\n‚è±Ô∏è EXPONENTIAL ANALYSIS (Time Between Events):\")\n",
    "lambda_rate = lambda_requests  # Same Œª for time between events\n",
    "\n",
    "# Time calculations\n",
    "mean_time_between = 1 / lambda_rate\n",
    "prob_wait_more_than_10_seconds = np.exp(-lambda_rate * (10/60))  # Convert to minutes\n",
    "median_wait_time = np.log(2) / lambda_rate\n",
    "\n",
    "print(f\"1. Average time between requests: {mean_time_between*60:.2f} seconds\")\n",
    "print(f\"2. P(wait > 10 seconds) = {prob_wait_more_than_10_seconds:.4f}\")\n",
    "print(f\"3. Median waiting time: {median_wait_time*60:.2f} seconds\")\n",
    "\n",
    "# Memoryless property demonstration\n",
    "time_already_waited = 5/60  # 5 seconds in minutes\n",
    "prob_wait_additional_10 = np.exp(-lambda_rate * (10/60))  # Same as above!\n",
    "print(f\"4. Memoryless property: P(wait additional 10s | already waited 5s) = {prob_wait_additional_10:.4f}\")\n",
    "print(f\"   This equals P(wait > 10s) - exponential is memoryless!\")\n",
    "\n",
    "# Comprehensive Visualization\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Poisson PMF\n",
    "k_values = np.arange(0, 30)\n",
    "poisson_pmf = stats.poisson.pmf(k_values, lambda_requests)\n",
    "\n",
    "ax1.bar(k_values, poisson_pmf, alpha=0.7, color='skyblue')\n",
    "ax1.axvline(lambda_requests, color='red', linestyle='--', label=f'Mean = {lambda_requests}')\n",
    "ax1.axvline(capacity_99_percent, color='orange', linestyle='--', label=f'99% capacity = {capacity_99_percent:.0f}')\n",
    "ax1.set_xlabel('Number of Requests per Minute')\n",
    "ax1.set_ylabel('Probability')\n",
    "ax1.set_title('Poisson Distribution: Request Counts')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Exponential PDF\n",
    "t_values = np.linspace(0, 0.5, 1000)  # 0 to 30 seconds\n",
    "exponential_pdf = stats.expon.pdf(t_values, scale=1/lambda_rate)\n",
    "\n",
    "ax2.plot(t_values, exponential_pdf, 'g-', linewidth=2, label='PDF')\n",
    "ax2.fill_between(t_values[t_values > 10/60], exponential_pdf[t_values > 10/60], \n",
    "                 alpha=0.3, color='red', label=f'P(wait > 10s) = {prob_wait_more_than_10_seconds:.3f}')\n",
    "ax2.axvline(mean_time_between, color='red', linestyle='--', label=f'Mean = {mean_time_between*60:.1f}s')\n",
    "ax2.set_xlabel('Time Between Requests (minutes)')\n",
    "ax2.set_ylabel('Probability Density')\n",
    "ax2.set_title('Exponential Distribution: Time Between Requests')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Poisson process simulation\n",
    "np.random.seed(42)\n",
    "simulation_time = 60  # 60 minutes\n",
    "arrival_times = []\n",
    "current_time = 0\n",
    "\n",
    "while current_time < simulation_time:\n",
    "    # Time to next event follows exponential distribution\n",
    "    time_to_next = np.random.exponential(1/lambda_rate)\n",
    "    current_time += time_to_next\n",
    "    if current_time < simulation_time:\n",
    "        arrival_times.append(current_time)\n",
    "\n",
    "# Count events in each minute\n",
    "minute_counts = []\n",
    "for minute in range(simulation_time):\n",
    "    count = sum(1 for t in arrival_times if minute <= t < minute + 1)\n",
    "    minute_counts.append(count)\n",
    "\n",
    "ax3.plot(range(simulation_time), minute_counts, 'b-', alpha=0.7, label='Simulated')\n",
    "ax3.axhline(lambda_requests, color='red', linestyle='--', label=f'Expected = {lambda_requests}')\n",
    "ax3.set_xlabel('Time (minutes)')\n",
    "ax3.set_ylabel('Requests per Minute')\n",
    "ax3.set_title('Poisson Process Simulation (60 minutes)')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Comparison with Normal approximation\n",
    "# For large Œª, Poisson approximates Normal\n",
    "k_large = np.arange(0, 50)\n",
    "poisson_large = stats.poisson.pmf(k_large, 25)  # Œª = 25\n",
    "normal_approx = stats.norm.pdf(k_large, 25, np.sqrt(25))\n",
    "\n",
    "ax4.plot(k_large, poisson_large, 'bo-', alpha=0.6, label='Poisson(Œª=25)')\n",
    "ax4.plot(k_large, normal_approx, 'r-', linewidth=2, label='Normal Approximation')\n",
    "ax4.set_xlabel('k')\n",
    "ax4.set_ylabel('Probability/Density')\n",
    "ax4.set_title('Poisson ‚Üí Normal for Large Œª')\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ML Applications\n",
    "print(f\"\\nü§ñ ML APPLICATIONS:\")\n",
    "print(f\"POISSON:\")\n",
    "print(f\"  ‚Ä¢ Recommendation systems: User interaction counts\")\n",
    "print(f\"  ‚Ä¢ Text analysis: Word frequencies in documents\")  \n",
    "print(f\"  ‚Ä¢ Computer vision: Object counts in images\")\n",
    "print(f\"  ‚Ä¢ Time series: Event count forecasting\")\n",
    "\n",
    "print(f\"\\nEXPONENTIAL:\")\n",
    "print(f\"  ‚Ä¢ Survival analysis: Time until churn/failure\")\n",
    "print(f\"  ‚Ä¢ Reliability modeling: Component lifetimes\")\n",
    "print(f\"  ‚Ä¢ Queue optimization: Service time modeling\")\n",
    "print(f\"  ‚Ä¢ Reinforcement learning: Time between rewards\")\n",
    "\n",
    "# Real-world example: Customer service modeling\n",
    "print(f\"\\nüè¢ CUSTOMER SERVICE EXAMPLE:\")\n",
    "avg_calls_per_hour = 30\n",
    "service_time_minutes = 2\n",
    "\n",
    "# How many representatives needed?\n",
    "lambda_calls = avg_calls_per_hour / 60  # per minute\n",
    "service_rate = 1 / service_time_minutes  # per minute\n",
    "\n",
    "print(f\"Call arrival rate: {lambda_calls:.3f} calls/minute\")\n",
    "print(f\"Service rate per rep: {service_rate:.3f} customers/minute\")\n",
    "print(f\"Minimum reps needed: {lambda_calls / service_rate:.1f}\")\n",
    "print(f\"For stable queue, need > {lambda_calls / service_rate:.0f} representatives\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b2ce04",
   "metadata": {},
   "source": [
    "# 3. üß™ Statistical Inference: Making Decisions with Data\n",
    "\n",
    "Statistical inference allows us to make conclusions about populations based on sample data. This is **crucial** for ML because:\n",
    "\n",
    "- **Model evaluation**: Are performance differences statistically significant?\n",
    "- **Feature selection**: Which features truly matter?\n",
    "- **A/B testing**: Is the new model actually better?\n",
    "- **Uncertainty quantification**: How confident are our predictions?\n",
    "\n",
    "## 3.1 Hypothesis Testing Framework\n",
    "\n",
    "**The Scientific Method for Data Science**\n",
    "\n",
    "### Steps:\n",
    "1. **Formulate Hypotheses**: H‚ÇÄ (null) vs H‚ÇÅ (alternative)\n",
    "2. **Choose Significance Level** (Œ±): Typically 0.05, 0.01, or 0.001\n",
    "3. **Select Test Statistic**: z-test, t-test, œá¬≤-test, etc.\n",
    "4. **Calculate p-value**: P(observing data | H‚ÇÄ is true)\n",
    "5. **Make Decision**: Reject H‚ÇÄ if p-value < Œ±\n",
    "\n",
    "### Error Types:\n",
    "- **Type I Error (Œ±)**: Reject true H‚ÇÄ (false positive)\n",
    "- **Type II Error (Œ≤)**: Fail to reject false H‚ÇÄ (false negative)  \n",
    "- **Power (1-Œ≤)**: Correctly reject false H‚ÇÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77272c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypothesis Testing: Drug Effectiveness Study\n",
    "print(\"üß™ HYPOTHESIS TESTING: DRUG EFFECTIVENESS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Scenario: Testing if new drug reduces recovery time\n",
    "# Control group (standard treatment): Œº = 12 days, œÉ = 3 days, n = 30\n",
    "# Treatment group (new drug): observed mean = 10.5 days, œÉ = 2.8 days, n = 35\n",
    "\n",
    "mu_control = 12\n",
    "sigma_control = 3\n",
    "n_control = 30\n",
    "\n",
    "observed_treatment = 10.5\n",
    "sigma_treatment = 2.8\n",
    "n_treatment = 35\n",
    "\n",
    "print(f\"Control: Œº = {mu_control} days, œÉ = {sigma_control} days, n = {n_control}\")\n",
    "print(f\"Treatment: xÃÑ = {observed_treatment} days, œÉ = {sigma_treatment} days, n = {n_treatment}\")\n",
    "\n",
    "# Step 1: Formulate hypotheses\n",
    "print(f\"\\nüìù STEP 1: FORMULATE HYPOTHESES\")\n",
    "print(f\"H‚ÇÄ: Œº_treatment = Œº_control = {mu_control} (no difference)\")\n",
    "print(f\"H‚ÇÅ: Œº_treatment < Œº_control (new drug is better)\")\n",
    "print(f\"This is a one-tailed test (left-tailed)\")\n",
    "\n",
    "# Step 2: Choose significance level\n",
    "alpha = 0.05\n",
    "print(f\"\\nüìä STEP 2: SIGNIFICANCE LEVEL\")\n",
    "print(f\"Œ± = {alpha} (5% chance of Type I error)\")\n",
    "\n",
    "# Step 3: Choose test statistic\n",
    "# Since we have different sample sizes and known œÉ, use two-sample z-test\n",
    "print(f\"\\nüßÆ STEP 3: TEST STATISTIC\")\n",
    "print(f\"Using two-sample z-test (known population variances)\")\n",
    "\n",
    "# Calculate pooled standard error\n",
    "se_pooled = np.sqrt((sigma_control**2 / n_control) + (sigma_treatment**2 / n_treatment))\n",
    "z_stat = (observed_treatment - mu_control) / se_pooled\n",
    "\n",
    "print(f\"Standard Error: {se_pooled:.4f}\")\n",
    "print(f\"Z-statistic: {z_stat:.4f}\")\n",
    "\n",
    "# Step 4: Calculate p-value\n",
    "p_value = stats.norm.cdf(z_stat)  # Left-tailed test\n",
    "\n",
    "print(f\"\\nüìà STEP 4: P-VALUE\")\n",
    "print(f\"P-value = {p_value:.6f}\")\n",
    "\n",
    "# Step 5: Make decision\n",
    "reject_null = p_value < alpha\n",
    "print(f\"\\n‚öñÔ∏è STEP 5: DECISION\")\n",
    "print(f\"P-value ({p_value:.6f}) {'<' if reject_null else '>='} Œ± ({alpha})\")\n",
    "print(f\"Decision: {'Reject H‚ÇÄ' if reject_null else 'Fail to reject H‚ÇÄ'}\")\n",
    "print(f\"Conclusion: {'Significant evidence that new drug reduces recovery time' if reject_null else 'Insufficient evidence of improvement'}\")\n",
    "\n",
    "# Calculate effect size (Cohen's d)\n",
    "pooled_std = np.sqrt(((n_control-1)*sigma_control**2 + (n_treatment-1)*sigma_treatment**2) / (n_control + n_treatment - 2))\n",
    "cohens_d = (mu_control - observed_treatment) / pooled_std\n",
    "\n",
    "print(f\"\\nüìè EFFECT SIZE\")\n",
    "print(f\"Cohen's d = {cohens_d:.3f}\")\n",
    "if cohens_d < 0.2:\n",
    "    effect_interpretation = \"negligible\"\n",
    "elif cohens_d < 0.5:\n",
    "    effect_interpretation = \"small\"\n",
    "elif cohens_d < 0.8:\n",
    "    effect_interpretation = \"medium\"\n",
    "else:\n",
    "    effect_interpretation = \"large\"\n",
    "print(f\"Effect size: {effect_interpretation}\")\n",
    "\n",
    "# Power analysis\n",
    "from scipy.stats import norm\n",
    "z_critical = norm.ppf(alpha)  # Left-tailed critical value\n",
    "true_difference = mu_control - observed_treatment\n",
    "power = norm.cdf((z_critical * se_pooled + true_difference) / se_pooled)\n",
    "\n",
    "print(f\"\\n‚ö° POWER ANALYSIS\")\n",
    "print(f\"Power of the test: {power:.3f} or {power:.1%}\")\n",
    "\n",
    "# Comprehensive visualization\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Null and alternative distributions\n",
    "x_range = np.linspace(8, 16, 1000)\n",
    "null_dist = stats.norm(mu_control, se_pooled)\n",
    "alt_dist = stats.norm(observed_treatment, se_pooled)\n",
    "\n",
    "ax1.plot(x_range, null_dist.pdf(x_range), 'b-', linewidth=2, label='H‚ÇÄ: Œº = 12')\n",
    "ax1.plot(x_range, alt_dist.pdf(x_range), 'r-', linewidth=2, label='H‚ÇÅ: Œº = 10.5')\n",
    "\n",
    "# Critical region\n",
    "critical_value = mu_control + z_critical * se_pooled\n",
    "x_critical = x_range[x_range <= critical_value]\n",
    "ax1.fill_between(x_critical, null_dist.pdf(x_critical), alpha=0.3, color='red', label=f'Rejection region (Œ±={alpha})')\n",
    "\n",
    "# Observed value\n",
    "ax1.axvline(observed_treatment, color='darkred', linestyle='--', linewidth=2, label=f'Observed: {observed_treatment}')\n",
    "\n",
    "ax1.set_xlabel('Mean Recovery Time (days)')\n",
    "ax1.set_ylabel('Probability Density')\n",
    "ax1.set_title('Null vs Alternative Hypothesis')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. P-value visualization\n",
    "z_range = np.linspace(-4, 4, 1000)\n",
    "standard_normal = stats.norm(0, 1)\n",
    "\n",
    "ax2.plot(z_range, standard_normal.pdf(z_range), 'k-', linewidth=2, label='Standard Normal')\n",
    "z_fill = z_range[z_range <= z_stat]\n",
    "ax2.fill_between(z_fill, standard_normal.pdf(z_fill), alpha=0.3, color='red', label=f'P-value = {p_value:.6f}')\n",
    "ax2.axvline(z_stat, color='red', linestyle='--', linewidth=2, label=f'Z = {z_stat:.3f}')\n",
    "ax2.axvline(z_critical, color='orange', linestyle='--', linewidth=2, label=f'Critical value = {z_critical:.3f}')\n",
    "\n",
    "ax2.set_xlabel('Z-score')\n",
    "ax2.set_ylabel('Probability Density')\n",
    "ax2.set_title('P-value Calculation')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Type I and Type II errors illustration\n",
    "# Type I error (Œ±)\n",
    "ax3.plot(x_range, null_dist.pdf(x_range), 'b-', linewidth=2, label='Null Distribution')\n",
    "x_type1 = x_range[x_range <= critical_value]\n",
    "ax3.fill_between(x_type1, null_dist.pdf(x_type1), alpha=0.3, color='red', label=f'Type I Error (Œ± = {alpha})')\n",
    "\n",
    "# Type II error (Œ≤)\n",
    "ax3.plot(x_range, alt_dist.pdf(x_range), 'r-', linewidth=2, label='Alternative Distribution')\n",
    "x_type2 = x_range[x_range > critical_value]\n",
    "ax3.fill_between(x_type2, alt_dist.pdf(x_type2), alpha=0.3, color='blue', label=f'Type II Error (Œ≤ = {1-power:.3f})')\n",
    "\n",
    "ax3.axvline(critical_value, color='black', linestyle='--', alpha=0.7, label='Decision boundary')\n",
    "ax3.set_xlabel('Mean Recovery Time (days)')\n",
    "ax3.set_ylabel('Probability Density')\n",
    "ax3.set_title('Type I and Type II Errors')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Power analysis across effect sizes\n",
    "effect_sizes = np.linspace(0, 2, 100)\n",
    "powers = []\n",
    "\n",
    "for d in effect_sizes:\n",
    "    true_mean = mu_control - d * pooled_std\n",
    "    power_d = norm.cdf((z_critical * se_pooled + (mu_control - true_mean)) / se_pooled)\n",
    "    powers.append(power_d)\n",
    "\n",
    "ax4.plot(effect_sizes, powers, 'g-', linewidth=2, label='Power Curve')\n",
    "ax4.axhline(y=0.8, color='orange', linestyle='--', label='Desired Power = 0.8')\n",
    "ax4.axvline(x=cohens_d, color='red', linestyle='--', label=f'Our Effect Size = {cohens_d:.3f}')\n",
    "ax4.axhline(y=power, color='red', linestyle=':', alpha=0.7, label=f'Our Power = {power:.3f}')\n",
    "\n",
    "ax4.set_xlabel(\"Effect Size (Cohen's d)\")\n",
    "ax4.set_ylabel('Statistical Power')\n",
    "ax4.set_title('Power Analysis')\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Practical considerations\n",
    "print(f\"\\nüí° PRACTICAL CONSIDERATIONS:\")\n",
    "print(f\"1. Statistical significance ‚â† practical significance\")\n",
    "print(f\"2. Consider effect size, not just p-value\")\n",
    "print(f\"3. Replication is important for confirming results\")\n",
    "print(f\"4. Multiple testing requires correction (Bonferroni, FDR)\")\n",
    "\n",
    "# ML implications\n",
    "print(f\"\\nü§ñ ML IMPLICATIONS:\")\n",
    "print(f\"‚Ä¢ Model comparison: Are accuracy differences significant?\")\n",
    "print(f\"‚Ä¢ Feature selection: Which features significantly improve performance?\")\n",
    "print(f\"‚Ä¢ Hyperparameter tuning: Statistical validation of improvements\")\n",
    "print(f\"‚Ä¢ Cross-validation: Statistical assessment of model stability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb2bf41",
   "metadata": {},
   "source": [
    "## 3.2 üéØ Confidence Intervals: Quantifying Uncertainty\n",
    "\n",
    "**Understanding Confidence Intervals is crucial for ML because they tell us about the uncertainty in our estimates.**\n",
    "\n",
    "### Correct Interpretation:\n",
    "- **95% CI**: If we repeat the experiment many times, 95% of intervals will contain the true parameter\n",
    "- **NOT**: \"95% probability the parameter is in this interval\"\n",
    "\n",
    "### Why It Matters for ML:\n",
    "- **Model performance bounds**: What's the range of expected accuracy?\n",
    "- **Parameter estimation**: How certain are we about model coefficients?\n",
    "- **Prediction intervals**: What's the range of likely predictions?\n",
    "- **A/B testing**: What's the range of possible effect sizes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae7b943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confidence Intervals: Model Performance Analysis\n",
    "print(\"üéØ CONFIDENCE INTERVALS: MODEL PERFORMANCE\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Scenario: Machine learning model evaluation\n",
    "# We have accuracy scores from 10-fold cross-validation\n",
    "np.random.seed(42)\n",
    "cv_accuracies = [0.84, 0.87, 0.83, 0.89, 0.85, 0.88, 0.82, 0.86, 0.90, 0.84]\n",
    "n_folds = len(cv_accuracies)\n",
    "sample_mean = np.mean(cv_accuracies)\n",
    "sample_std = np.std(cv_accuracies, ddof=1)  # Sample standard deviation\n",
    "\n",
    "print(f\"Cross-validation accuracies: {cv_accuracies}\")\n",
    "print(f\"Sample mean: {sample_mean:.4f}\")\n",
    "print(f\"Sample std: {sample_std:.4f}\")\n",
    "print(f\"Number of folds: {n_folds}\")\n",
    "\n",
    "# Different confidence levels\n",
    "confidence_levels = [0.90, 0.95, 0.99]\n",
    "colors = ['lightblue', 'blue', 'darkblue']\n",
    "\n",
    "print(f\"\\nüìä CONFIDENCE INTERVALS:\")\n",
    "\n",
    "intervals = {}\n",
    "for conf_level, color in zip(confidence_levels, colors):\n",
    "    alpha = 1 - conf_level\n",
    "    \n",
    "    # For small samples, use t-distribution\n",
    "    t_critical = stats.t.ppf(1 - alpha/2, df=n_folds-1)\n",
    "    margin_error = t_critical * (sample_std / np.sqrt(n_folds))\n",
    "    \n",
    "    ci_lower = sample_mean - margin_error\n",
    "    ci_upper = sample_mean + margin_error\n",
    "    \n",
    "    intervals[conf_level] = (ci_lower, ci_upper, margin_error)\n",
    "    \n",
    "    print(f\"{conf_level:.0%} CI: [{ci_lower:.4f}, {ci_upper:.4f}] ¬± {margin_error:.4f}\")\n",
    "\n",
    "# Bootstrap confidence intervals (non-parametric approach)\n",
    "print(f\"\\nüîÑ BOOTSTRAP CONFIDENCE INTERVALS:\")\n",
    "n_bootstrap = 10000\n",
    "bootstrap_means = []\n",
    "\n",
    "for _ in range(n_bootstrap):\n",
    "    bootstrap_sample = np.random.choice(cv_accuracies, size=n_folds, replace=True)\n",
    "    bootstrap_means.append(np.mean(bootstrap_sample))\n",
    "\n",
    "bootstrap_means = np.array(bootstrap_means)\n",
    "\n",
    "for conf_level in confidence_levels:\n",
    "    alpha = 1 - conf_level\n",
    "    ci_lower_boot = np.percentile(bootstrap_means, 100 * alpha/2)\n",
    "    ci_upper_boot = np.percentile(bootstrap_means, 100 * (1 - alpha/2))\n",
    "    \n",
    "    print(f\"{conf_level:.0%} Bootstrap CI: [{ci_lower_boot:.4f}, {ci_upper_boot:.4f}]\")\n",
    "\n",
    "# Visualization\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Confidence intervals comparison\n",
    "y_pos = range(len(confidence_levels))\n",
    "means = [sample_mean] * len(confidence_levels)\n",
    "errors = [intervals[cl][2] for cl in confidence_levels]\n",
    "\n",
    "bars = ax1.barh(y_pos, means, xerr=errors, capsize=10, \n",
    "                color=colors, alpha=0.7, label='T-distribution CI')\n",
    "\n",
    "ax1.axvline(sample_mean, color='red', linestyle='--', linewidth=2, label=f'Sample mean = {sample_mean:.4f}')\n",
    "ax1.set_yticks(y_pos)\n",
    "ax1.set_yticklabels([f'{cl:.0%}' for cl in confidence_levels])\n",
    "ax1.set_xlabel('Model Accuracy')\n",
    "ax1.set_title('Confidence Intervals at Different Levels')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Add text annotations\n",
    "for i, (cl, (lower, upper, _)) in enumerate(intervals.items()):\n",
    "    ax1.text(sample_mean + 0.01, i, f'[{lower:.3f}, {upper:.3f}]', \n",
    "             va='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "# 2. Bootstrap distribution\n",
    "ax2.hist(bootstrap_means, bins=50, density=True, alpha=0.7, color='skyblue', \n",
    "         label=f'Bootstrap means (n={n_bootstrap})')\n",
    "ax2.axvline(sample_mean, color='red', linestyle='--', linewidth=2, label=f'Original mean = {sample_mean:.4f}')\n",
    "\n",
    "# Add confidence interval bounds\n",
    "for conf_level, color in zip([0.95], ['blue']):\n",
    "    alpha = 1 - conf_level\n",
    "    ci_lower_boot = np.percentile(bootstrap_means, 100 * alpha/2)\n",
    "    ci_upper_boot = np.percentile(bootstrap_means, 100 * (1 - alpha/2))\n",
    "    ax2.axvline(ci_lower_boot, color=color, linestyle=':', alpha=0.7)\n",
    "    ax2.axvline(ci_upper_boot, color=color, linestyle=':', alpha=0.7)\n",
    "\n",
    "ax2.set_xlabel('Bootstrap Sample Means')\n",
    "ax2.set_ylabel('Density')\n",
    "ax2.set_title('Bootstrap Distribution of Sample Mean')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Effect of sample size on CI width\n",
    "sample_sizes = range(5, 101, 5)\n",
    "ci_widths = []\n",
    "\n",
    "for n in sample_sizes:\n",
    "    t_crit = stats.t.ppf(0.975, df=n-1)  # 95% CI\n",
    "    margin = t_crit * (sample_std / np.sqrt(n))\n",
    "    ci_widths.append(2 * margin)  # Total width\n",
    "\n",
    "ax3.plot(sample_sizes, ci_widths, 'g-', linewidth=2, label='95% CI Width')\n",
    "ax3.axhline(y=2*intervals[0.95][2], color='red', linestyle='--', \n",
    "            label=f'Our CI width = {2*intervals[0.95][2]:.4f}')\n",
    "ax3.axvline(x=n_folds, color='red', linestyle='--', alpha=0.7, label=f'Our sample size = {n_folds}')\n",
    "\n",
    "ax3.set_xlabel('Sample Size')\n",
    "ax3.set_ylabel('CI Width')\n",
    "ax3.set_title('Effect of Sample Size on Confidence Interval Width')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Coverage probability simulation\n",
    "true_accuracy = 0.85  # Assume this is the true population mean\n",
    "coverage_counts = {cl: 0 for cl in confidence_levels}\n",
    "n_simulations = 1000\n",
    "\n",
    "for _ in range(n_simulations):\n",
    "    # Simulate a new sample\n",
    "    simulated_sample = np.random.normal(true_accuracy, sample_std, n_folds)\n",
    "    sim_mean = np.mean(simulated_sample)\n",
    "    sim_std = np.std(simulated_sample, ddof=1)\n",
    "    \n",
    "    for conf_level in confidence_levels:\n",
    "        alpha = 1 - conf_level\n",
    "        t_crit = stats.t.ppf(1 - alpha/2, df=n_folds-1)\n",
    "        margin = t_crit * (sim_std / np.sqrt(n_folds))\n",
    "        \n",
    "        ci_lower = sim_mean - margin\n",
    "        ci_upper = sim_mean + margin\n",
    "        \n",
    "        if ci_lower <= true_accuracy <= ci_upper:\n",
    "            coverage_counts[conf_level] += 1\n",
    "\n",
    "coverage_rates = [coverage_counts[cl] / n_simulations for cl in confidence_levels]\n",
    "\n",
    "ax4.bar(range(len(confidence_levels)), coverage_rates, color=colors, alpha=0.7, \n",
    "        label='Observed Coverage')\n",
    "ax4.plot(range(len(confidence_levels)), confidence_levels, 'ro-', linewidth=2, \n",
    "         label='Expected Coverage')\n",
    "\n",
    "ax4.set_xticks(range(len(confidence_levels)))\n",
    "ax4.set_xticklabels([f'{cl:.0%}' for cl in confidence_levels])\n",
    "ax4.set_ylabel('Coverage Rate')\n",
    "ax4.set_title(f'CI Coverage Verification ({n_simulations} simulations)')\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "# Add text annotations\n",
    "for i, (expected, observed) in enumerate(zip(confidence_levels, coverage_rates)):\n",
    "    ax4.text(i, observed + 0.01, f'{observed:.3f}', ha='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Practical implications\n",
    "print(f\"\\nüí° PRACTICAL IMPLICATIONS:\")\n",
    "print(f\"1. Wider CIs = more uncertainty (need more data or accept uncertainty)\")\n",
    "print(f\"2. If CI doesn't include baseline, difference is significant\")\n",
    "print(f\"3. Bootstrap CIs don't assume normal distribution\")\n",
    "print(f\"4. Overlap of CIs ‚â† no significant difference (common misconception)\")\n",
    "\n",
    "print(f\"\\nü§ñ ML APPLICATIONS:\")\n",
    "print(f\"‚Ä¢ Model selection: Compare CI ranges, not just point estimates\")\n",
    "print(f\"‚Ä¢ Hyperparameter tuning: Use CIs to assess improvement significance\")\n",
    "print(f\"‚Ä¢ Feature importance: CIs around importance scores\")\n",
    "print(f\"‚Ä¢ Prediction intervals: Range of likely predictions for new data\")\n",
    "\n",
    "# Prediction intervals example\n",
    "print(f\"\\nüîÆ PREDICTION INTERVAL EXAMPLE:\")\n",
    "# For a new model evaluation, what accuracy range can we expect?\n",
    "prediction_std = np.sqrt(sample_std**2 + sample_std**2/n_folds)  # Additional uncertainty\n",
    "t_crit_pred = stats.t.ppf(0.975, df=n_folds-1)\n",
    "pred_margin = t_crit_pred * prediction_std\n",
    "\n",
    "pred_lower = sample_mean - pred_margin\n",
    "pred_upper = sample_mean + pred_margin\n",
    "\n",
    "print(f\"95% Prediction interval for next accuracy: [{pred_lower:.4f}, {pred_upper:.4f}]\")\n",
    "print(f\"This accounts for both estimation uncertainty AND individual variation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76b6f96",
   "metadata": {},
   "source": [
    "# 4. ‚öñÔ∏è Bayesian vs Frequentist: Two Philosophical Approaches\n",
    "\n",
    "**This is one of the most important conceptual distinctions in statistics and ML!**\n",
    "\n",
    "## 4.1 üèõÔ∏è Frequentist Approach\n",
    "\n",
    "### Philosophy:\n",
    "- **Parameters are fixed** unknown constants\n",
    "- **Probability** = long-run frequency  \n",
    "- **Data is random** due to sampling process\n",
    "- **Objectivity** through procedures that work \"in the long run\"\n",
    "\n",
    "### Methods:\n",
    "- Maximum Likelihood Estimation (MLE)\n",
    "- Hypothesis testing with p-values\n",
    "- Confidence intervals\n",
    "- ANOVA, regression\n",
    "\n",
    "### Pros:\n",
    "‚úÖ Objective, no subjective priors  \n",
    "‚úÖ Well-established, widely accepted  \n",
    "‚úÖ Clear decision procedures  \n",
    "‚úÖ Good for large sample sizes\n",
    "\n",
    "### Cons:\n",
    "‚ùå No direct probability statements about parameters  \n",
    "‚ùå Doesn't incorporate prior knowledge  \n",
    "‚ùå P-values often misinterpreted  \n",
    "‚ùå Multiple testing problems\n",
    "\n",
    "## 4.2 üß† Bayesian Approach\n",
    "\n",
    "### Philosophy:\n",
    "- **Parameters are random** variables with distributions\n",
    "- **Probability** = degree of belief\n",
    "- **Data is fixed** once observed  \n",
    "- **Subjectivity** acknowledged and incorporated\n",
    "\n",
    "### Methods:\n",
    "- Bayes' theorem for parameter updating\n",
    "- Posterior distributions\n",
    "- Credible intervals\n",
    "- Bayesian model comparison\n",
    "\n",
    "### Pros:\n",
    "‚úÖ Intuitive probability interpretation  \n",
    "‚úÖ Incorporates prior knowledge  \n",
    "‚úÖ Sequential updating with new data  \n",
    "‚úÖ Natural uncertainty quantification  \n",
    "‚úÖ No multiple testing issues\n",
    "\n",
    "### Cons:\n",
    "‚ùå Subjective prior choice  \n",
    "‚ùå Computationally intensive  \n",
    "‚ùå Can be complex to implement  \n",
    "‚ùå Prior sensitivity concerns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293913d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayesian vs Frequentist: Coin Bias Estimation\n",
    "print(\"‚öñÔ∏è BAYESIAN VS FREQUENTIST: COIN BIAS ESTIMATION\")\n",
    "print(\"=\"*55)\n",
    "\n",
    "# Scenario: Estimating the bias of a coin\n",
    "# Observed: 7 heads in 10 flips\n",
    "observed_heads = 7\n",
    "n_flips = 10\n",
    "\n",
    "print(f\"Observed: {observed_heads} heads in {n_flips} flips\")\n",
    "print(f\"Question: What is the probability that the coin is fair (p = 0.5)?\")\n",
    "\n",
    "# FREQUENTIST APPROACH\n",
    "print(f\"\\nüèõÔ∏è FREQUENTIST APPROACH:\")\n",
    "print(f\"=\" * 25)\n",
    "\n",
    "# Point estimate (MLE)\n",
    "mle_estimate = observed_heads / n_flips\n",
    "print(f\"MLE estimate: pÃÇ = {mle_estimate}\")\n",
    "\n",
    "# Confidence interval\n",
    "alpha = 0.05\n",
    "z_critical = stats.norm.ppf(1 - alpha/2)\n",
    "se = np.sqrt(mle_estimate * (1 - mle_estimate) / n_flips)\n",
    "ci_lower = mle_estimate - z_critical * se\n",
    "ci_upper = mle_estimate + z_critical * se\n",
    "\n",
    "print(f\"95% Confidence Interval: [{ci_lower:.3f}, {ci_upper:.3f}]\")\n",
    "\n",
    "# Hypothesis test for fairness\n",
    "p_null = 0.5\n",
    "z_stat = (mle_estimate - p_null) / np.sqrt(p_null * (1 - p_null) / n_flips)\n",
    "p_value_freq = 2 * (1 - stats.norm.cdf(abs(z_stat)))\n",
    "\n",
    "print(f\"Hypothesis test H‚ÇÄ: p = 0.5\")\n",
    "print(f\"Z-statistic: {z_stat:.3f}\")\n",
    "print(f\"P-value: {p_value_freq:.4f}\")\n",
    "print(f\"Conclusion: {'Reject H‚ÇÄ' if p_value_freq < 0.05 else 'Fail to reject H‚ÇÄ'} at Œ± = 0.05\")\n",
    "\n",
    "print(f\"\\nFrequentist interpretation:\")\n",
    "print(f\"‚Ä¢ We estimate p = {mle_estimate}, but p is a fixed unknown value\")\n",
    "print(f\"‚Ä¢ CI means: 95% of such intervals contain the true p\")\n",
    "print(f\"‚Ä¢ We cannot say 'P(p is fair) = ...'\")\n",
    "\n",
    "# BAYESIAN APPROACH\n",
    "print(f\"\\nüß† BAYESIAN APPROACH:\")\n",
    "print(f\"=\" * 20)\n",
    "\n",
    "# Prior distribution: Beta(2, 2) - slightly favors fairness\n",
    "prior_alpha = 2\n",
    "prior_beta = 2\n",
    "print(f\"Prior: Beta({prior_alpha}, {prior_beta}) - slightly favors fairness\")\n",
    "\n",
    "# Posterior distribution: Beta(prior_alpha + heads, prior_beta + tails)\n",
    "posterior_alpha = prior_alpha + observed_heads\n",
    "posterior_beta = prior_beta + (n_flips - observed_heads)\n",
    "print(f\"Posterior: Beta({posterior_alpha}, {posterior_beta})\")\n",
    "\n",
    "# Posterior statistics\n",
    "posterior_mean = posterior_alpha / (posterior_alpha + posterior_beta)\n",
    "posterior_var = (posterior_alpha * posterior_beta) / ((posterior_alpha + posterior_beta)**2 * (posterior_alpha + posterior_beta + 1))\n",
    "posterior_std = np.sqrt(posterior_var)\n",
    "\n",
    "print(f\"Posterior mean: {posterior_mean:.3f}\")\n",
    "print(f\"Posterior std: {posterior_std:.3f}\")\n",
    "\n",
    "# Credible interval\n",
    "credible_lower = stats.beta.ppf(0.025, posterior_alpha, posterior_beta)\n",
    "credible_upper = stats.beta.ppf(0.975, posterior_alpha, posterior_beta)\n",
    "print(f\"95% Credible Interval: [{credible_lower:.3f}, {credible_upper:.3f}]\")\n",
    "\n",
    "# Probability that coin is fair (exactly 0.5)\n",
    "# For continuous distributions, we look at a small interval around 0.5\n",
    "fair_prob = stats.beta.cdf(0.51, posterior_alpha, posterior_beta) - stats.beta.cdf(0.49, posterior_alpha, posterior_beta)\n",
    "print(f\"P(0.49 < p < 0.51 | data): {fair_prob:.4f}\")\n",
    "\n",
    "# Probability that coin is biased towards heads (p > 0.5)\n",
    "bias_prob = 1 - stats.beta.cdf(0.5, posterior_alpha, posterior_beta)\n",
    "print(f\"P(p > 0.5 | data): {bias_prob:.4f}\")\n",
    "\n",
    "print(f\"\\nBayesian interpretation:\")\n",
    "print(f\"‚Ä¢ We have a full distribution over possible values of p\")\n",
    "print(f\"‚Ä¢ We can make direct probability statements about p\")\n",
    "print(f\"‚Ä¢ Prior beliefs are updated with evidence\")\n",
    "\n",
    "# Comprehensive Visualization\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Prior vs Posterior\n",
    "p_values = np.linspace(0, 1, 1000)\n",
    "prior_pdf = stats.beta.pdf(p_values, prior_alpha, prior_beta)\n",
    "posterior_pdf = stats.beta.pdf(p_values, posterior_alpha, posterior_beta)\n",
    "\n",
    "ax1.plot(p_values, prior_pdf, 'b-', linewidth=2, label=f'Prior: Beta({prior_alpha}, {prior_beta})')\n",
    "ax1.plot(p_values, posterior_pdf, 'r-', linewidth=2, label=f'Posterior: Beta({posterior_alpha}, {posterior_beta})')\n",
    "ax1.axvline(0.5, color='black', linestyle='--', alpha=0.7, label='Fair coin (p=0.5)')\n",
    "ax1.axvline(mle_estimate, color='green', linestyle='--', alpha=0.7, label=f'MLE = {mle_estimate}')\n",
    "ax1.axvline(posterior_mean, color='red', linestyle=':', alpha=0.7, label=f'Posterior mean = {posterior_mean:.3f}')\n",
    "\n",
    "ax1.fill_between(p_values, 0, prior_pdf, alpha=0.2, color='blue')\n",
    "ax1.fill_between(p_values, 0, posterior_pdf, alpha=0.2, color='red')\n",
    "\n",
    "ax1.set_xlabel('Coin Bias (p)')\n",
    "ax1.set_ylabel('Probability Density')\n",
    "ax1.set_title('Prior vs Posterior Distribution')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Confidence vs Credible intervals\n",
    "methods = ['Frequentist\\n(95% CI)', 'Bayesian\\n(95% CrI)']\n",
    "estimates = [mle_estimate, posterior_mean]\n",
    "lower_bounds = [ci_lower, credible_lower]\n",
    "upper_bounds = [ci_upper, credible_upper]\n",
    "\n",
    "x_pos = np.arange(len(methods))\n",
    "bars = ax2.bar(x_pos, estimates, yerr=[np.array(estimates) - np.array(lower_bounds), \n",
    "                                       np.array(upper_bounds) - np.array(estimates)], \n",
    "               capsize=10, color=['blue', 'red'], alpha=0.7)\n",
    "\n",
    "ax2.axhline(y=0.5, color='black', linestyle='--', alpha=0.7, label='Fair coin')\n",
    "ax2.set_ylabel('Estimated Coin Bias')\n",
    "ax2.set_title('Confidence Interval vs Credible Interval')\n",
    "ax2.set_xticks(x_pos)\n",
    "ax2.set_xticklabels(methods)\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Add value annotations\n",
    "for i, (est, lower, upper) in enumerate(zip(estimates, lower_bounds, upper_bounds)):\n",
    "    ax2.text(i, est + 0.05, f'{est:.3f}\\n[{lower:.3f}, {upper:.3f}]', \n",
    "             ha='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "# 3. Sequential updating (Bayesian)\n",
    "# Simulate sequential coin flips\n",
    "np.random.seed(42)\n",
    "true_p = 0.7  # True coin bias (unknown in practice)\n",
    "flips = np.random.binomial(1, true_p, 20)\n",
    "cumulative_heads = np.cumsum(flips)\n",
    "cumulative_total = np.arange(1, 21)\n",
    "\n",
    "# Track posterior means as data accumulates\n",
    "posterior_means = []\n",
    "credible_lowers = []\n",
    "credible_uppers = []\n",
    "\n",
    "for i, (heads, total) in enumerate(zip(cumulative_heads, cumulative_total)):\n",
    "    post_alpha = prior_alpha + heads\n",
    "    post_beta = prior_beta + (total - heads)\n",
    "    \n",
    "    post_mean = post_alpha / (post_alpha + post_beta)\n",
    "    post_lower = stats.beta.ppf(0.025, post_alpha, post_beta)\n",
    "    post_upper = stats.beta.ppf(0.975, post_alpha, post_beta)\n",
    "    \n",
    "    posterior_means.append(post_mean)\n",
    "    credible_lowers.append(post_lower)\n",
    "    credible_uppers.append(post_upper)\n",
    "\n",
    "ax3.plot(cumulative_total, posterior_means, 'r-', linewidth=2, label='Posterior Mean')\n",
    "ax3.fill_between(cumulative_total, credible_lowers, credible_uppers, \n",
    "                 alpha=0.3, color='red', label='95% Credible Interval')\n",
    "ax3.axhline(y=true_p, color='green', linestyle='--', linewidth=2, label=f'True p = {true_p}')\n",
    "ax3.axhline(y=0.5, color='black', linestyle='--', alpha=0.5, label='Fair coin')\n",
    "\n",
    "ax3.set_xlabel('Number of Flips')\n",
    "ax3.set_ylabel('Estimated Coin Bias')\n",
    "ax3.set_title('Sequential Bayesian Updating')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Prior sensitivity analysis\n",
    "priors = [\n",
    "    (1, 1, 'Uniform', 'blue'),\n",
    "    (2, 2, 'Slightly informed', 'green'),\n",
    "    (5, 5, 'Strongly fair', 'orange'),\n",
    "    (1, 3, 'Biased against heads', 'purple')\n",
    "]\n",
    "\n",
    "for alpha_p, beta_p, label, color in priors:\n",
    "    post_alpha = alpha_p + observed_heads\n",
    "    post_beta = beta_p + (n_flips - observed_heads)\n",
    "    post_pdf = stats.beta.pdf(p_values, post_alpha, post_beta)\n",
    "    ax4.plot(p_values, post_pdf, linewidth=2, label=f'{label}: Beta({alpha_p},{beta_p})', color=color)\n",
    "\n",
    "ax4.axvline(0.5, color='black', linestyle='--', alpha=0.7, label='Fair coin')\n",
    "ax4.axvline(mle_estimate, color='red', linestyle=':', alpha=0.7, label=f'MLE = {mle_estimate}')\n",
    "\n",
    "ax4.set_xlabel('Coin Bias (p)')\n",
    "ax4.set_ylabel('Posterior Density')\n",
    "ax4.set_title('Prior Sensitivity Analysis')\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# When to use each approach\n",
    "print(f\"\\nüéØ WHEN TO USE EACH APPROACH:\")\n",
    "print(f\"\\nFrequentist:\")\n",
    "print(f\"‚úì Large sample sizes\")\n",
    "print(f\"‚úì Regulatory requirements (FDA, etc.)\")\n",
    "print(f\"‚úì Need for 'objective' analysis\")\n",
    "print(f\"‚úì Well-established procedures\")\n",
    "print(f\"‚úì Multiple testing scenarios\")\n",
    "\n",
    "print(f\"\\nBayesian:\")\n",
    "print(f\"‚úì Small sample sizes\")\n",
    "print(f\"‚úì Prior information available\")\n",
    "print(f\"‚úì Sequential decision making\")\n",
    "print(f\"‚úì Uncertainty quantification important\")\n",
    "print(f\"‚úì Natural parameter interpretation needed\")\n",
    "\n",
    "print(f\"\\nü§ñ ML IMPLICATIONS:\")\n",
    "print(f\"‚Ä¢ Bayesian methods increasingly popular in ML\")\n",
    "print(f\"‚Ä¢ Bayesian neural networks for uncertainty\")\n",
    "print(f\"‚Ä¢ Gaussian processes are inherently Bayesian\")\n",
    "print(f\"‚Ä¢ A/B testing benefits from both approaches\")\n",
    "print(f\"‚Ä¢ AutoML often uses Bayesian optimization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9fa32b",
   "metadata": {},
   "source": [
    "# üí™ Practice Project 1: A/B Testing with Statistical Significance\n",
    "\n",
    "**Objective**: Build a complete A/B testing framework that properly handles statistical significance, power analysis, and practical considerations.\n",
    "\n",
    "This project demonstrates:\n",
    "- Proper experimental design\n",
    "- Statistical testing procedures  \n",
    "- Power analysis and sample size calculation\n",
    "- Multiple testing corrections\n",
    "- Business interpretation of results\n",
    "\n",
    "**Real-world scenario**: E-commerce website testing a new checkout design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ed9816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A/B Testing Framework Implementation\n",
    "print(\"üí™ A/B TESTING WITH STATISTICAL SIGNIFICANCE\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "class ABTestAnalyzer:\n",
    "    def __init__(self, alpha=0.05, power=0.8):\n",
    "        \"\"\"\n",
    "        Initialize A/B test analyzer\n",
    "        \n",
    "        Parameters:\n",
    "        alpha: Type I error rate (significance level)\n",
    "        power: Desired statistical power (1 - Type II error rate)\n",
    "        \"\"\"\n",
    "        self.alpha = alpha\n",
    "        self.power = power\n",
    "        self.results = {}\n",
    "    \n",
    "    def calculate_sample_size(self, baseline_rate, effect_size, test_type='two-sided'):\n",
    "        \"\"\"\n",
    "        Calculate required sample size for desired power\n",
    "        \n",
    "        Parameters:\n",
    "        baseline_rate: Current conversion rate\n",
    "        effect_size: Minimum detectable effect (as proportion)\n",
    "        test_type: 'two-sided' or 'one-sided'\n",
    "        \"\"\"\n",
    "        from statsmodels.stats.power import zt_ind_solve_power\n",
    "        \n",
    "        # Convert to standardized effect size\n",
    "        p1 = baseline_rate\n",
    "        p2 = baseline_rate * (1 + effect_size)\n",
    "        pooled_p = (p1 + p2) / 2\n",
    "        standardized_effect = (p2 - p1) / np.sqrt(pooled_p * (1 - pooled_p))\n",
    "        \n",
    "        # Adjust alpha for one-sided test\n",
    "        alpha_adj = self.alpha if test_type == 'two-sided' else self.alpha\n",
    "        \n",
    "        # Calculate sample size\n",
    "        sample_size = zt_ind_solve_power(\n",
    "            effect_size=standardized_effect,\n",
    "            power=self.power,\n",
    "            alpha=alpha_adj,\n",
    "            ratio=1.0  # Equal group sizes\n",
    "        )\n",
    "        \n",
    "        return int(np.ceil(sample_size))\n",
    "    \n",
    "    def analyze_test(self, control_conversions, control_visitors, \n",
    "                     treatment_conversions, treatment_visitors):\n",
    "        \"\"\"\n",
    "        Analyze A/B test results\n",
    "        \n",
    "        Returns comprehensive analysis including:\n",
    "        - Statistical test results\n",
    "        - Effect size\n",
    "        - Confidence intervals\n",
    "        - Business metrics\n",
    "        \"\"\"\n",
    "        # Basic statistics\n",
    "        p_control = control_conversions / control_visitors\n",
    "        p_treatment = treatment_conversions / treatment_visitors\n",
    "        \n",
    "        # Two-proportion z-test\n",
    "        pooled_p = (control_conversions + treatment_conversions) / (control_visitors + treatment_visitors)\n",
    "        se_diff = np.sqrt(pooled_p * (1 - pooled_p) * (1/control_visitors + 1/treatment_visitors))\n",
    "        \n",
    "        z_stat = (p_treatment - p_control) / se_diff\n",
    "        p_value = 2 * (1 - stats.norm.cdf(abs(z_stat)))\n",
    "        \n",
    "        # Confidence interval for difference\n",
    "        se_diff_ci = np.sqrt((p_control * (1 - p_control) / control_visitors) + \n",
    "                            (p_treatment * (1 - p_treatment) / treatment_visitors))\n",
    "        z_critical = stats.norm.ppf(1 - self.alpha/2)\n",
    "        \n",
    "        diff = p_treatment - p_control\n",
    "        ci_lower = diff - z_critical * se_diff_ci\n",
    "        ci_upper = diff + z_critical * se_diff_ci\n",
    "        \n",
    "        # Effect size (relative improvement)\n",
    "        relative_improvement = (p_treatment - p_control) / p_control if p_control > 0 else 0\n",
    "        \n",
    "        # Statistical power (post-hoc)\n",
    "        observed_effect = abs(diff) / np.sqrt(pooled_p * (1 - pooled_p))\n",
    "        power_achieved = 1 - stats.norm.cdf(stats.norm.ppf(1 - self.alpha/2) - observed_effect * np.sqrt(control_visitors/2))\n",
    "        \n",
    "        self.results = {\n",
    "            'control_rate': p_control,\n",
    "            'treatment_rate': p_treatment,\n",
    "            'absolute_difference': diff,\n",
    "            'relative_improvement': relative_improvement,\n",
    "            'z_statistic': z_stat,\n",
    "            'p_value': p_value,\n",
    "            'significant': p_value < self.alpha,\n",
    "            'ci_lower': ci_lower,\n",
    "            'ci_upper': ci_upper,\n",
    "            'power_achieved': power_achieved,\n",
    "            'sample_size_control': control_visitors,\n",
    "            'sample_size_treatment': treatment_visitors\n",
    "        }\n",
    "        \n",
    "        return self.results\n",
    "    \n",
    "    def generate_report(self):\n",
    "        \"\"\"Generate comprehensive A/B test report\"\"\"\n",
    "        if not self.results:\n",
    "            return \"No test results available. Run analyze_test() first.\"\n",
    "        \n",
    "        r = self.results\n",
    "        \n",
    "        report = f\"\"\"\n",
    "        üß™ A/B TEST RESULTS REPORT\n",
    "        ={'='*40}\n",
    "        \n",
    "        üìä BASIC STATISTICS:\n",
    "        Control conversion rate:     {r['control_rate']:.4f} ({r['control_rate']:.2%})\n",
    "        Treatment conversion rate:   {r['treatment_rate']:.4f} ({r['treatment_rate']:.2%})\n",
    "        Absolute difference:         {r['absolute_difference']:.4f}\n",
    "        Relative improvement:        {r['relative_improvement']:.2%}\n",
    "        \n",
    "        üßÆ STATISTICAL TEST:\n",
    "        Z-statistic:                 {r['z_statistic']:.4f}\n",
    "        P-value:                     {r['p_value']:.6f}\n",
    "        Significance level (Œ±):      {self.alpha}\n",
    "        Result:                      {'SIGNIFICANT' if r['significant'] else 'NOT SIGNIFICANT'}\n",
    "        \n",
    "        üìè CONFIDENCE INTERVAL:\n",
    "        95% CI for difference:       [{r['ci_lower']:.4f}, {r['ci_upper']:.4f}]\n",
    "        \n",
    "        ‚ö° POWER ANALYSIS:\n",
    "        Achieved power:              {r['power_achieved']:.3f}\n",
    "        Sample sizes:                Control: {r['sample_size_control']}, Treatment: {r['sample_size_treatment']}\n",
    "        \n",
    "        üíº BUSINESS INTERPRETATION:\n",
    "        {'‚úÖ Statistically significant improvement detected!' if r['significant'] else '‚ùå No statistically significant difference detected.'}\n",
    "        {f\"Expected improvement: {r['relative_improvement']:.1%}\" if r['significant'] else \"\"}\n",
    "        \"\"\"\n",
    "        \n",
    "        return report\n",
    "\n",
    "# Practical Example: E-commerce Checkout Optimization\n",
    "print(\"üõí E-COMMERCE CHECKOUT OPTIMIZATION\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Initialize analyzer\n",
    "ab_test = ABTestAnalyzer(alpha=0.05, power=0.8)\n",
    "\n",
    "# Experimental design phase\n",
    "baseline_conversion = 0.12  # Current 12% conversion rate\n",
    "minimum_effect = 0.10       # Want to detect 10% relative improvement (1.2 percentage points)\n",
    "\n",
    "print(f\"Baseline conversion rate: {baseline_conversion:.1%}\")\n",
    "print(f\"Minimum detectable effect: {minimum_effect:.1%} relative improvement\")\n",
    "\n",
    "# Calculate required sample size\n",
    "required_n = ab_test.calculate_sample_size(baseline_conversion, minimum_effect)\n",
    "print(f\"Required sample size per group: {required_n:,} visitors\")\n",
    "\n",
    "# Simulate experiment results (in practice, these come from your data)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Control group: original checkout\n",
    "control_visitors = 15000\n",
    "control_conversions = np.random.binomial(control_visitors, baseline_conversion)\n",
    "\n",
    "# Treatment group: new checkout (actually 8% better)\n",
    "true_improvement = 0.08\n",
    "treatment_rate = baseline_conversion * (1 + true_improvement)\n",
    "treatment_visitors = 15000\n",
    "treatment_conversions = np.random.binomial(treatment_visitors, treatment_rate)\n",
    "\n",
    "print(f\"\\nüìä EXPERIMENT RESULTS:\")\n",
    "print(f\"Control: {control_conversions}/{control_visitors} conversions\")\n",
    "print(f\"Treatment: {treatment_conversions}/{treatment_visitors} conversions\")\n",
    "\n",
    "# Analyze results\n",
    "results = ab_test.analyze_test(control_conversions, control_visitors,\n",
    "                               treatment_conversions, treatment_visitors)\n",
    "\n",
    "# Print comprehensive report\n",
    "print(ab_test.generate_report())\n",
    "\n",
    "# Advanced Analysis: Sequential Testing\n",
    "print(f\"\\nüîÑ SEQUENTIAL TESTING ANALYSIS\")\n",
    "print(f\"=\"*35)\n",
    "\n",
    "# Simulate data collection over time\n",
    "days = 14\n",
    "daily_visitors_per_group = control_visitors // days\n",
    "\n",
    "cumulative_results = []\n",
    "sequential_p_values = []\n",
    "\n",
    "for day in range(1, days + 1):\n",
    "    # Cumulative data up to this day\n",
    "    cum_control_visitors = daily_visitors_per_group * day\n",
    "    cum_control_conversions = np.random.binomial(cum_control_visitors, baseline_conversion)\n",
    "    \n",
    "    cum_treatment_visitors = daily_visitors_per_group * day  \n",
    "    cum_treatment_conversions = np.random.binomial(cum_treatment_visitors, treatment_rate)\n",
    "    \n",
    "    # Analyze cumulative data\n",
    "    day_results = ab_test.analyze_test(cum_control_conversions, cum_control_visitors,\n",
    "                                       cum_treatment_conversions, cum_treatment_visitors)\n",
    "    \n",
    "    cumulative_results.append(day_results)\n",
    "    sequential_p_values.append(day_results['p_value'])\n",
    "    \n",
    "    if day_results['significant']:\n",
    "        print(f\"Day {day}: SIGNIFICANT (p = {day_results['p_value']:.4f})\")\n",
    "\n",
    "# Visualizations\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Conversion rates comparison\n",
    "groups = ['Control', 'Treatment']\n",
    "rates = [results['control_rate'], results['treatment_rate']]\n",
    "errors = [np.sqrt(results['control_rate'] * (1 - results['control_rate']) / control_visitors),\n",
    "          np.sqrt(results['treatment_rate'] * (1 - results['treatment_rate']) / treatment_visitors)]\n",
    "\n",
    "bars = ax1.bar(groups, rates, yerr=errors, capsize=10, color=['blue', 'red'], alpha=0.7)\n",
    "ax1.set_ylabel('Conversion Rate')\n",
    "ax1.set_title('Final Conversion Rates with 95% CI')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Add value annotations\n",
    "for i, (rate, error) in enumerate(zip(rates, errors)):\n",
    "    ax1.text(i, rate + error + 0.002, f'{rate:.3f}', ha='center', fontweight='bold')\n",
    "\n",
    "# 2. Effect size visualization\n",
    "effect_mean = results['absolute_difference']\n",
    "effect_ci = [results['ci_lower'], results['ci_upper']]\n",
    "\n",
    "ax2.axhline(y=0, color='black', linestyle='--', alpha=0.5, label='No effect')\n",
    "ax2.bar(['Effect Size'], [effect_mean], \n",
    "        yerr=[[effect_mean - effect_ci[0]], [effect_ci[1] - effect_mean]], \n",
    "        capsize=10, color='green', alpha=0.7)\n",
    "ax2.set_ylabel('Difference in Conversion Rate')\n",
    "ax2.set_title('Treatment Effect with 95% CI')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Add annotation\n",
    "significance_text = 'Significant' if results['significant'] else 'Not Significant'\n",
    "ax2.text(0, effect_mean + 0.005, f'{effect_mean:.4f}\\n({significance_text})', \n",
    "         ha='center', fontweight='bold')\n",
    "\n",
    "# 3. Sequential p-values\n",
    "days_list = list(range(1, days + 1))\n",
    "ax3.plot(days_list, sequential_p_values, 'bo-', linewidth=2, markersize=6)\n",
    "ax3.axhline(y=0.05, color='red', linestyle='--', label='Œ± = 0.05')\n",
    "ax3.set_xlabel('Day')\n",
    "ax3.set_ylabel('P-value')\n",
    "ax3.set_title('Sequential Testing: P-values Over Time')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "ax3.set_yscale('log')\n",
    "\n",
    "# 4. Power curve analysis\n",
    "effect_sizes = np.linspace(0, 0.3, 100)\n",
    "sample_sizes = [5000, 10000, 15000, 20000]\n",
    "\n",
    "for n in sample_sizes:\n",
    "    powers = []\n",
    "    for effect in effect_sizes:\n",
    "        # Standardized effect size\n",
    "        p1 = baseline_conversion\n",
    "        p2 = baseline_conversion * (1 + effect)\n",
    "        pooled_p = (p1 + p2) / 2\n",
    "        if pooled_p > 0 and pooled_p < 1:\n",
    "            std_effect = (p2 - p1) / np.sqrt(pooled_p * (1 - pooled_p))\n",
    "            power = 1 - stats.norm.cdf(stats.norm.ppf(1 - 0.025) - std_effect * np.sqrt(n/2))\n",
    "        else:\n",
    "            power = 0\n",
    "        powers.append(power)\n",
    "    \n",
    "    ax4.plot(effect_sizes * 100, powers, linewidth=2, label=f'n = {n:,}')\n",
    "\n",
    "ax4.axhline(y=0.8, color='red', linestyle='--', alpha=0.7, label='Power = 0.8')\n",
    "ax4.axvline(x=true_improvement * 100, color='green', linestyle='--', alpha=0.7, \n",
    "            label=f'True effect = {true_improvement:.1%}')\n",
    "ax4.set_xlabel('Relative Effect Size (%)')\n",
    "ax4.set_ylabel('Statistical Power')\n",
    "ax4.set_title('Power Analysis: Effect Size vs Sample Size')\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Business recommendations\n",
    "print(f\"\\nüíº BUSINESS RECOMMENDATIONS:\")\n",
    "if results['significant']:\n",
    "    print(f\"‚úÖ IMPLEMENT the new checkout design\")\n",
    "    print(f\"üìà Expected improvement: {results['relative_improvement']:.1%}\")\n",
    "    print(f\"üí∞ With {control_visitors + treatment_visitors:,} monthly visitors:\")\n",
    "    \n",
    "    current_monthly_conversions = (control_visitors + treatment_visitors) * baseline_conversion\n",
    "    new_monthly_conversions = (control_visitors + treatment_visitors) * results['treatment_rate']\n",
    "    additional_conversions = new_monthly_conversions - current_monthly_conversions\n",
    "    \n",
    "    print(f\"   Current conversions: {current_monthly_conversions:.0f}/month\")\n",
    "    print(f\"   Expected conversions: {new_monthly_conversions:.0f}/month\")\n",
    "    print(f\"   Additional conversions: {additional_conversions:.0f}/month\")\n",
    "else:\n",
    "    print(f\"‚ùå DO NOT implement - insufficient evidence\")\n",
    "    print(f\"üîç Consider: longer test duration, larger sample size, or different design\")\n",
    "\n",
    "print(f\"\\nüéØ KEY LEARNINGS:\")\n",
    "print(f\"1. Pre-plan sample sizes using power analysis\")\n",
    "print(f\"2. Don't stop early unless using proper sequential testing procedures\")\n",
    "print(f\"3. Effect size matters as much as statistical significance\")\n",
    "print(f\"4. Confidence intervals provide range of plausible effects\")\n",
    "print(f\"5. Business context determines practical significance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45b990d",
   "metadata": {},
   "source": [
    "# üí™ Practice Project 2: Spam Detection using Bayesian Methods\n",
    "\n",
    "**Objective**: Build a complete spam detection system using Bayesian principles, implementing Naive Bayes from scratch and exploring advanced Bayesian concepts.\n",
    "\n",
    "This project demonstrates:\n",
    "- Naive Bayes classifier implementation\n",
    "- Bayesian reasoning in action\n",
    "- Text preprocessing for ML\n",
    "- Model evaluation and interpretation\n",
    "- Uncertainty quantification\n",
    "- Online learning with Bayesian updates\n",
    "\n",
    "**Real-world application**: Email spam filtering system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2590be16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayesian Spam Detection System\n",
    "print(\"üí™ SPAM DETECTION USING BAYESIAN METHODS\")\n",
    "print(\"=\"*45)\n",
    "\n",
    "import re\n",
    "from collections import defaultdict, Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import string\n",
    "\n",
    "class BayesianSpamDetector:\n",
    "    def __init__(self, smoothing=1.0):\n",
    "        \"\"\"\n",
    "        Bayesian Spam Detector using Naive Bayes\n",
    "        \n",
    "        Parameters:\n",
    "        smoothing: Laplace smoothing parameter (alpha)\n",
    "        \"\"\"\n",
    "        self.smoothing = smoothing\n",
    "        self.vocab = set()\n",
    "        self.class_priors = {}\n",
    "        self.word_likelihoods = {}\n",
    "        self.total_docs = 0\n",
    "        self.class_counts = defaultdict(int)\n",
    "        self.word_counts = defaultdict(lambda: defaultdict(int))\n",
    "        \n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"Clean and tokenize text\"\"\"\n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Remove punctuation and numbers\n",
    "        text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "        text = re.sub(r'\\d+', '', text)\n",
    "        \n",
    "        # Split into words and remove short words\n",
    "        words = [word for word in text.split() if len(word) > 2]\n",
    "        \n",
    "        return words\n",
    "    \n",
    "    def fit(self, documents, labels):\n",
    "        \"\"\"\n",
    "        Train the Bayesian classifier\n",
    "        \n",
    "        Parameters:\n",
    "        documents: List of text documents\n",
    "        labels: List of corresponding labels (0=ham, 1=spam)\n",
    "        \"\"\"\n",
    "        self.total_docs = len(documents)\n",
    "        \n",
    "        # Count class occurrences\n",
    "        for label in labels:\n",
    "            self.class_counts[label] += 1\n",
    "        \n",
    "        # Calculate class priors P(Class)\n",
    "        for class_label, count in self.class_counts.items():\n",
    "            self.class_priors[class_label] = count / self.total_docs\n",
    "        \n",
    "        # Count word occurrences per class\n",
    "        all_words = set()\n",
    "        \n",
    "        for doc, label in zip(documents, labels):\n",
    "            words = self.preprocess_text(doc)\n",
    "            for word in words:\n",
    "                self.word_counts[label][word] += 1\n",
    "                all_words.add(word)\n",
    "        \n",
    "        self.vocab = all_words\n",
    "        vocab_size = len(self.vocab)\n",
    "        \n",
    "        # Calculate word likelihoods P(Word|Class) with smoothing\n",
    "        self.word_likelihoods = defaultdict(dict)\n",
    "        \n",
    "        for class_label in self.class_counts:\n",
    "            total_words_in_class = sum(self.word_counts[class_label].values())\n",
    "            \n",
    "            for word in self.vocab:\n",
    "                # Laplace smoothing\n",
    "                word_count = self.word_counts[class_label][word]\n",
    "                self.word_likelihoods[class_label][word] = \\\n",
    "                    (word_count + self.smoothing) / (total_words_in_class + self.smoothing * vocab_size)\n",
    "    \n",
    "    def predict_proba(self, document):\n",
    "        \"\"\"\n",
    "        Predict probability of each class for a document\n",
    "        \n",
    "        Returns:\n",
    "        Dictionary with class probabilities\n",
    "        \"\"\"\n",
    "        words = self.preprocess_text(document)\n",
    "        \n",
    "        # Calculate log probabilities to avoid underflow\n",
    "        log_probs = {}\n",
    "        \n",
    "        for class_label in self.class_priors:\n",
    "            # Start with log prior\n",
    "            log_prob = np.log(self.class_priors[class_label])\n",
    "            \n",
    "            # Add log likelihoods for each word\n",
    "            for word in words:\n",
    "                if word in self.vocab:\n",
    "                    log_prob += np.log(self.word_likelihoods[class_label][word])\n",
    "                else:\n",
    "                    # Handle unseen words with smoothing\n",
    "                    vocab_size = len(self.vocab)\n",
    "                    total_words_in_class = sum(self.word_counts[class_label].values())\n",
    "                    unseen_prob = self.smoothing / (total_words_in_class + self.smoothing * vocab_size)\n",
    "                    log_prob += np.log(unseen_prob)\n",
    "            \n",
    "            log_probs[class_label] = log_prob\n",
    "        \n",
    "        # Convert back to probabilities and normalize\n",
    "        max_log_prob = max(log_probs.values())\n",
    "        probs = {k: np.exp(v - max_log_prob) for k, v in log_probs.items()}\n",
    "        total_prob = sum(probs.values())\n",
    "        probs = {k: v / total_prob for k, v in probs.items()}\n",
    "        \n",
    "        return probs\n",
    "    \n",
    "    def predict(self, documents):\n",
    "        \"\"\"Predict class labels for documents\"\"\"\n",
    "        predictions = []\n",
    "        \n",
    "        for doc in documents:\n",
    "            probs = self.predict_proba(doc)\n",
    "            predicted_class = max(probs, key=probs.get)\n",
    "            predictions.append(predicted_class)\n",
    "        \n",
    "        return predictions\n",
    "    \n",
    "    def get_most_informative_features(self, n_features=20):\n",
    "        \"\"\"Get most informative words for classification\"\"\"\n",
    "        if not self.word_likelihoods:\n",
    "            return []\n",
    "        \n",
    "        feature_scores = []\n",
    "        \n",
    "        for word in self.vocab:\n",
    "            # Calculate log ratio of likelihoods\n",
    "            spam_prob = self.word_likelihoods[1].get(word, 1e-10)\n",
    "            ham_prob = self.word_likelihoods[0].get(word, 1e-10)\n",
    "            \n",
    "            score = np.log(spam_prob / ham_prob)\n",
    "            feature_scores.append((word, score))\n",
    "        \n",
    "        # Sort by absolute score\n",
    "        feature_scores.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "        \n",
    "        return feature_scores[:n_features]\n",
    "\n",
    "# Create synthetic email dataset for demonstration\n",
    "def generate_email_dataset(n_samples=1000):\n",
    "    \"\"\"Generate synthetic email dataset\"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Spam indicators\n",
    "    spam_words = ['free', 'money', 'win', 'prize', 'urgent', 'limited', 'offer', \n",
    "                  'click', 'buy', 'cheap', 'discount', 'deal', 'save', 'cash',\n",
    "                  'lottery', 'winner', 'congratulations', 'bonus', 'gift']\n",
    "    \n",
    "    # Ham indicators  \n",
    "    ham_words = ['meeting', 'project', 'team', 'work', 'office', 'client',\n",
    "                 'report', 'deadline', 'schedule', 'conference', 'presentation',\n",
    "                 'budget', 'analysis', 'discussion', 'feedback', 'review']\n",
    "    \n",
    "    # Neutral words\n",
    "    neutral_words = ['the', 'and', 'to', 'of', 'in', 'for', 'with', 'on', \n",
    "                     'is', 'are', 'will', 'have', 'this', 'that', 'from']\n",
    "    \n",
    "    emails = []\n",
    "    labels = []\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        if i < n_samples // 2:  # First half are ham\n",
    "            label = 0\n",
    "            # Mostly ham words with some neutral\n",
    "            words = (np.random.choice(ham_words, size=np.random.randint(10, 25)) +\n",
    "                    np.random.choice(neutral_words, size=np.random.randint(5, 15)) +\n",
    "                    np.random.choice(spam_words, size=np.random.randint(0, 3)))  # Few spam words\n",
    "        else:  # Second half are spam\n",
    "            label = 1\n",
    "            # Mostly spam words with some neutral\n",
    "            words = (np.random.choice(spam_words, size=np.random.randint(10, 25)) +\n",
    "                    np.random.choice(neutral_words, size=np.random.randint(5, 15)) +\n",
    "                    np.random.choice(ham_words, size=np.random.randint(0, 3)))  # Few ham words\n",
    "        \n",
    "        email = ' '.join(words)\n",
    "        emails.append(email)\n",
    "        labels.append(label)\n",
    "    \n",
    "    return emails, labels\n",
    "\n",
    "# Generate dataset\n",
    "print(\"üìß GENERATING SYNTHETIC EMAIL DATASET\")\n",
    "emails, labels = generate_email_dataset(2000)\n",
    "\n",
    "# Split into train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    emails, labels, test_size=0.3, random_state=42, stratify=labels\n",
    ")\n",
    "\n",
    "print(f\"Training set: {len(X_train)} emails ({sum(y_train)} spam)\")\n",
    "print(f\"Test set: {len(X_test)} emails ({sum(y_test)} spam)\")\n",
    "\n",
    "# Train our Bayesian spam detector\n",
    "print(f\"\\nüß† TRAINING BAYESIAN SPAM DETECTOR\")\n",
    "spam_detector = BayesianSpamDetector(smoothing=1.0)\n",
    "spam_detector.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Vocabulary size: {len(spam_detector.vocab)}\")\n",
    "print(f\"Class priors: {spam_detector.class_priors}\")\n",
    "\n",
    "# Make predictions\n",
    "y_pred = spam_detector.predict(X_test)\n",
    "y_proba = [spam_detector.predict_proba(email)[1] for email in X_test]  # Spam probabilities\n",
    "\n",
    "# Evaluate performance\n",
    "print(f\"\\nüìä MODEL EVALUATION\")\n",
    "print(\"=\"*25)\n",
    "print(classification_report(y_test, y_pred, target_names=['Ham', 'Spam']))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(f\"{'':>10} {'Ham':>8} {'Spam':>8}\")\n",
    "print(f\"{'Ham':<10} {cm[0,0]:>8} {cm[0,1]:>8}\")\n",
    "print(f\"{'Spam':<10} {cm[1,0]:>8} {cm[1,1]:>8}\")\n",
    "\n",
    "# AUC score\n",
    "auc_score = roc_auc_score(y_test, y_proba)\n",
    "print(f\"\\nAUC Score: {auc_score:.4f}\")\n",
    "\n",
    "# Most informative features\n",
    "print(f\"\\nüîç MOST INFORMATIVE FEATURES\")\n",
    "print(\"=\"*35)\n",
    "top_features = spam_detector.get_most_informative_features(15)\n",
    "\n",
    "print(f\"{'Word':<15} {'Log Ratio':<12} {'Favors'}\")\n",
    "print(\"-\" * 35)\n",
    "for word, score in top_features:\n",
    "    favor = \"SPAM\" if score > 0 else \"HAM\"\n",
    "    print(f\"{word:<15} {score:>8.3f}    {favor}\")\n",
    "\n",
    "# Visualizations\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Confusion Matrix Heatmap\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Ham', 'Spam'], yticklabels=['Ham', 'Spam'], ax=ax1)\n",
    "ax1.set_title('Confusion Matrix')\n",
    "ax1.set_ylabel('True Label')\n",
    "ax1.set_xlabel('Predicted Label')\n",
    "\n",
    "# 2. ROC Curve\n",
    "fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "ax2.plot(fpr, tpr, linewidth=2, label=f'Bayesian Classifier (AUC = {auc_score:.3f})')\n",
    "ax2.plot([0, 1], [0, 1], 'k--', alpha=0.5, label='Random Classifier')\n",
    "ax2.set_xlabel('False Positive Rate')\n",
    "ax2.set_ylabel('True Positive Rate')\n",
    "ax2.set_title('ROC Curve')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Probability distribution by class\n",
    "spam_probs = [spam_detector.predict_proba(email)[1] for email, label in zip(X_test, y_test) if label == 1]\n",
    "ham_probs = [spam_detector.predict_proba(email)[1] for email, label in zip(X_test, y_test) if label == 0]\n",
    "\n",
    "ax3.hist(ham_probs, bins=20, alpha=0.7, label='Ham emails', color='blue', density=True)\n",
    "ax3.hist(spam_probs, bins=20, alpha=0.7, label='Spam emails', color='red', density=True)\n",
    "ax3.axvline(x=0.5, color='black', linestyle='--', alpha=0.7, label='Decision threshold')\n",
    "ax3.set_xlabel('Predicted Spam Probability')\n",
    "ax3.set_ylabel('Density')\n",
    "ax3.set_title('Probability Distributions by True Class')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Feature importance (top spam/ham words)\n",
    "words, scores = zip(*top_features[:10])\n",
    "colors = ['red' if score > 0 else 'blue' for score in scores]\n",
    "\n",
    "bars = ax4.barh(range(len(words)), scores, color=colors, alpha=0.7)\n",
    "ax4.set_yticks(range(len(words)))\n",
    "ax4.set_yticklabels(words)\n",
    "ax4.set_xlabel('Log Likelihood Ratio (Spam/Ham)')\n",
    "ax4.set_title('Most Informative Features')\n",
    "ax4.axvline(x=0, color='black', linestyle='-', alpha=0.5)\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Demonstration of Bayesian reasoning\n",
    "print(f\"\\nüß† BAYESIAN REASONING DEMONSTRATION\")\n",
    "print(\"=\"*45)\n",
    "\n",
    "# Example emails\n",
    "test_emails = [\n",
    "    \"congratulations you have won a free prize click here to claim your money\",\n",
    "    \"team meeting scheduled for tomorrow at 3pm in conference room\",\n",
    "    \"urgent limited time offer buy now and save big money\",\n",
    "    \"project deadline approaching please submit your report by friday\"\n",
    "]\n",
    "\n",
    "labels_demo = [\"Obvious Spam\", \"Clear Ham\", \"Obvious Spam\", \"Clear Ham\"]\n",
    "\n",
    "for email, expected in zip(test_emails, labels_demo):\n",
    "    probs = spam_detector.predict_proba(email)\n",
    "    prediction = \"SPAM\" if probs[1] > 0.5 else \"HAM\"\n",
    "    confidence = max(probs.values())\n",
    "    \n",
    "    print(f\"\\nEmail: \\\"{email}\\\"\")\n",
    "    print(f\"Expected: {expected}\")\n",
    "    print(f\"Prediction: {prediction} (confidence: {confidence:.3f})\")\n",
    "    print(f\"P(Ham): {probs[0]:.3f}, P(Spam): {probs[1]:.3f}\")\n",
    "\n",
    "# Online learning demonstration\n",
    "print(f\"\\nüîÑ ONLINE LEARNING DEMONSTRATION\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Simulate receiving new emails and updating beliefs\n",
    "new_emails = [\n",
    "    (\"buy cheap viagra online now\", 1),  # New spam\n",
    "    (\"quarterly budget review meeting\", 0),  # New ham\n",
    "    (\"free trial offer expires today\", 1),  # New spam\n",
    "]\n",
    "\n",
    "print(\"Initial model trained on 1400 emails\")\n",
    "initial_vocab_size = len(spam_detector.vocab)\n",
    "\n",
    "for email, true_label in new_emails:\n",
    "    # Predict before updating\n",
    "    old_probs = spam_detector.predict_proba(email)\n",
    "    \n",
    "    # Update model with new email (simple approach - retrain)\n",
    "    # In practice, you'd use more sophisticated online learning\n",
    "    X_train_updated = X_train + [email]\n",
    "    y_train_updated = y_train + [true_label]\n",
    "    \n",
    "    # Retrain (in practice, use incremental updates)\n",
    "    spam_detector.fit(X_train_updated, y_train_updated)\n",
    "    \n",
    "    # Predict after updating  \n",
    "    new_probs = spam_detector.predict_proba(email)\n",
    "    \n",
    "    print(f\"\\nNew email: \\\"{email}\\\"\")\n",
    "    print(f\"True label: {'SPAM' if true_label else 'HAM'}\")\n",
    "    print(f\"Before update - P(Spam): {old_probs[1]:.3f}\")\n",
    "    print(f\"After update  - P(Spam): {new_probs[1]:.3f}\")\n",
    "\n",
    "final_vocab_size = len(spam_detector.vocab)\n",
    "print(f\"\\nVocabulary grew from {initial_vocab_size} to {final_vocab_size} words\")\n",
    "\n",
    "# Compare with sklearn implementation\n",
    "print(f\"\\nüìä COMPARISON WITH SKLEARN NAIVE BAYES\")\n",
    "print(\"=\"*45)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Vectorize text for sklearn\n",
    "vectorizer = CountVectorizer(lowercase=True, stop_words='english', max_features=1000)\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "# Train sklearn model\n",
    "sklearn_nb = MultinomialNB(alpha=1.0)\n",
    "sklearn_nb.fit(X_train_vec, y_train)\n",
    "\n",
    "# Predictions\n",
    "sklearn_pred = sklearn_nb.predict(X_test_vec)\n",
    "sklearn_proba = sklearn_nb.predict_proba(X_test_vec)[:, 1]\n",
    "\n",
    "# Compare performance\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "our_accuracy = accuracy_score(y_test, y_pred)\n",
    "sklearn_accuracy = accuracy_score(y_test, sklearn_pred)\n",
    "\n",
    "print(f\"Our implementation accuracy: {our_accuracy:.4f}\")\n",
    "print(f\"Sklearn accuracy: {sklearn_accuracy:.4f}\")\n",
    "print(f\"Our AUC: {auc_score:.4f}\")\n",
    "print(f\"Sklearn AUC: {roc_auc_score(y_test, sklearn_proba):.4f}\")\n",
    "\n",
    "print(f\"\\nüéØ KEY LEARNINGS:\")\n",
    "print(f\"1. Naive Bayes assumes feature independence (often violated but works well)\")\n",
    "print(f\"2. Laplace smoothing handles unseen words gracefully\")\n",
    "print(f\"3. Log probabilities prevent numerical underflow\")\n",
    "print(f\"4. Bayesian methods provide natural uncertainty quantification\")\n",
    "print(f\"5. Online learning allows models to adapt to new data\")\n",
    "print(f\"6. Feature analysis reveals what the model learned\")\n",
    "\n",
    "print(f\"\\nüí° PRACTICAL CONSIDERATIONS:\")\n",
    "print(f\"‚Ä¢ Preprocessing is crucial (stemming, stop words, etc.)\")\n",
    "print(f\"‚Ä¢ Feature selection can improve performance\")\n",
    "print(f\"‚Ä¢ Ensemble methods can combine multiple Naive Bayes models\")\n",
    "print(f\"‚Ä¢ Regular retraining helps adapt to changing spam tactics\")\n",
    "print(f\"‚Ä¢ False positives (ham classified as spam) are very costly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe89d2b6",
   "metadata": {},
   "source": [
    "# üéØ Summary and Next Steps\n",
    "\n",
    "## üìö What You've Learned\n",
    "\n",
    "Congratulations! You've completed a comprehensive journey through probability and statistics for machine learning. Here's what you've mastered:\n",
    "\n",
    "### üßÆ Core Mathematical Concepts\n",
    "- **Conditional Probability**: The foundation of feature relationships in ML\n",
    "- **Bayes' Theorem**: The mathematical heart of Bayesian machine learning\n",
    "- **Key Distributions**: Normal, binomial, Poisson, and exponential distributions\n",
    "- **Statistical Inference**: Hypothesis testing and confidence intervals\n",
    "\n",
    "### üéØ Focus Areas Mastery\n",
    "- **Bayes' Theorem Applications**: From medical diagnosis to ML algorithms\n",
    "- **Uncertainty Quantification**: Understanding confidence in predictions\n",
    "- **Distribution Selection**: Choosing the right distribution for your data\n",
    "\n",
    "### üí™ Practical Skills\n",
    "- **A/B Testing**: Complete framework with statistical significance\n",
    "- **Bayesian Methods**: Spam detection using Naive Bayes from scratch\n",
    "- **Model Evaluation**: Proper statistical assessment of ML models\n",
    "\n",
    "## üöÄ Next Steps in Your ML Journey\n",
    "\n",
    "### Immediate Actions (This Week)\n",
    "1. **Practice with Real Data**: Apply these concepts to your own datasets\n",
    "2. **Implement Variations**: Try different priors, test statistics, distributions\n",
    "3. **Explore Edge Cases**: What happens with small samples? Skewed data?\n",
    "\n",
    "### Short-term Goals (Next Month)\n",
    "1. **Advanced Bayesian Methods**: \n",
    "   - Bayesian Networks\n",
    "   - Markov Chain Monte Carlo (MCMC)\n",
    "   - Variational Inference\n",
    "\n",
    "2. **Statistical Learning Theory**:\n",
    "   - Bias-variance tradeoff\n",
    "   - PAC learning\n",
    "   - VC dimension\n",
    "\n",
    "3. **Experimental Design**:\n",
    "   - Multi-armed bandits\n",
    "   - Causal inference\n",
    "   - Randomized controlled trials\n",
    "\n",
    "### Long-term Mastery (Next 3 Months)\n",
    "1. **Bayesian Machine Learning**:\n",
    "   - Gaussian Processes\n",
    "   - Bayesian Neural Networks\n",
    "   - Probabilistic Programming (PyMC, Stan)\n",
    "\n",
    "2. **Advanced Statistics**:\n",
    "   - Survival analysis\n",
    "   - Time series analysis\n",
    "   - Hierarchical models\n",
    "\n",
    "3. **Real-world Applications**:\n",
    "   - Contribute to open-source ML projects\n",
    "   - Publish your experiments and findings\n",
    "   - Build production-ready statistical systems\n",
    "\n",
    "## üõ†Ô∏è Recommended Tools and Resources\n",
    "\n",
    "### Python Libraries\n",
    "```python\n",
    "# Core statistics and probability\n",
    "import scipy.stats\n",
    "import statsmodels\n",
    "import numpy as np\n",
    "\n",
    "# Bayesian computing\n",
    "import pymc3  # or PyMC4/5\n",
    "import arviz\n",
    "import emcee\n",
    "\n",
    "# Advanced ML with uncertainty\n",
    "import gpytorch  # Gaussian Processes\n",
    "import pyro      # Probabilistic Programming\n",
    "```\n",
    "\n",
    "### Books for Deeper Learning\n",
    "1. **\"The Elements of Statistical Learning\"** - Hastie, Tibshirani, Friedman\n",
    "2. **\"Bayesian Data Analysis\"** - Gelman et al.\n",
    "3. **\"Pattern Recognition and Machine Learning\"** - Bishop\n",
    "4. **\"Information Theory, Inference, and Learning Algorithms\"** - MacKay\n",
    "\n",
    "### Online Courses\n",
    "1. **MIT 18.05**: Introduction to Probability and Statistics\n",
    "2. **Stanford CS229**: Machine Learning\n",
    "3. **Duke University**: Bayesian Statistics\n",
    "\n",
    "## üéñÔ∏è Assessment Checklist\n",
    "\n",
    "Rate your confidence (1-5) in each area:\n",
    "\n",
    "### Probability Fundamentals\n",
    "- [ ] Conditional probability calculations\n",
    "- [ ] Bayes' theorem applications  \n",
    "- [ ] Independence vs dependence\n",
    "- [ ] Law of total probability\n",
    "\n",
    "### Distributions\n",
    "- [ ] Normal distribution properties and applications\n",
    "- [ ] Binomial distribution for binary outcomes\n",
    "- [ ] Poisson distribution for count data\n",
    "- [ ] Exponential distribution for waiting times\n",
    "- [ ] Choosing appropriate distributions\n",
    "\n",
    "### Statistical Inference\n",
    "- [ ] Hypothesis testing framework\n",
    "- [ ] Type I/II errors and power\n",
    "- [ ] Confidence interval interpretation\n",
    "- [ ] P-value understanding\n",
    "\n",
    "### Bayesian vs Frequentist\n",
    "- [ ] Philosophical differences\n",
    "- [ ] When to use each approach\n",
    "- [ ] Prior selection and sensitivity\n",
    "- [ ] Posterior interpretation\n",
    "\n",
    "### Practical Applications\n",
    "- [ ] A/B testing design and analysis\n",
    "- [ ] Naive Bayes implementation\n",
    "- [ ] Model evaluation with uncertainty\n",
    "- [ ] Business interpretation of results\n",
    "\n",
    "**Target**: All items should be rated 4 or 5 before moving to advanced topics.\n",
    "\n",
    "## üåü Final Thoughts\n",
    "\n",
    "**Probability and statistics are not just mathematical tools‚Äîthey're the language of uncertainty and decision-making in the real world.**\n",
    "\n",
    "Remember:\n",
    "- **Start with the problem**, not the method\n",
    "- **Question your assumptions** about data and distributions\n",
    "- **Quantify uncertainty** in all your predictions\n",
    "- **Communicate results** in business-friendly terms\n",
    "- **Keep learning** as the field evolves rapidly\n",
    "\n",
    "You now have the foundation to tackle any machine learning problem with statistical rigor. The next step is to apply these concepts to real problems and continue building your expertise.\n",
    "\n",
    "**Happy learning and may your p-values be ever significant! üìä‚ú®**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb08058",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
